{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TRAIN notebook\ncometition : RSNA Screening Mammography Breast Cancer Detection  \nurl : https://www.kaggle.com/competitions/rsna-breast-cancer-detection  ","metadata":{}},{"cell_type":"markdown","source":"## import","metadata":{}},{"cell_type":"code","source":"!python -m pip install --no-index --find-links=/kaggle/input/dicom-whls pydicom pylibjpeg\n!python -m pip install --no-index --find-links=/kaggle/input/rsna-datasets/ENV python_gdcm\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\n\nimport datetime\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport PIL\nimport pydicom\nimport gdcm\nimport pylibjpeg\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:21.750602Z","iopub.execute_input":"2023-02-14T05:39:21.751076Z","iopub.status.idle":"2023-02-14T05:39:43.348374Z","shell.execute_reply.started":"2023-02-14T05:39:21.751025Z","shell.execute_reply":"2023-02-14T05:39:43.347256Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/dicom-whls\nRequirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\nRequirement already satisfied: pylibjpeg in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in links: /kaggle/input/rsna-datasets/ENV\nRequirement already satisfied: python_gdcm in /opt/conda/lib/python3.7/site-packages (3.0.21)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"timm.list_models(pretrained=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    def __init__(self, model_name:str='resnet26d', pretrained:bool=True,\n                 epochs:int=10, batch_size:int=32, size:int=512,\n                 seed:int=0):\n        self.model_name = model_name\n        self.pretrained = pretrained\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.size = size\n        self.seed = seed\n\nMODEL_NAME = 'vgg11'\nconfig = Config(model_name=MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:43.350390Z","iopub.execute_input":"2023-02-14T05:39:43.350749Z","iopub.status.idle":"2023-02-14T05:39:43.360901Z","shell.execute_reply.started":"2023-02-14T05:39:43.350713Z","shell.execute_reply":"2023-02-14T05:39:43.359888Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Image Processing","metadata":{}},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image\n","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:43.364427Z","iopub.execute_input":"2023-02-14T05:39:43.364725Z","iopub.status.idle":"2023-02-14T05:39:43.375392Z","shell.execute_reply.started":"2023-02-14T05:39:43.364697Z","shell.execute_reply":"2023-02-14T05:39:43.374084Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch Model Tools","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=3, verbose=False, path='checkpoint_model.pth'):\n        self.patience = patience #設定ストップカウンタ\n        self.verbose = verbose #表示の有無\n        self.counter = 0 #現在のカウンタ値\n        self.best_score = None #ベストスコア\n        self.early_stop = False #ストップフラグ\n        self.val_loss_min = np.Inf # 前回のベストスコア記憶用\n        self.path = path #ベストモデルの格納パス\n    \n    def __call__(self, val_loss, model):\n        score = -val_loss\n        \n        if self.best_score is None:\n            self.best_score = score\n            self.checkpoint(val_loss, model)\n        elif score < self.best_score:\n            self.counter += 1\n            if self.verbose:\n                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.checkpoint(val_loss, model)\n            self.counter = 0\n    \n    def checkpoint(self, val_loss, model):\n        if self.verbose:\n            print(f'validation loss decreased({self.val_loss_min:.6f} ---> {val_loss:.6f}). saving model....')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n\nclass TrainDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        f = self.df.filename.tolist()[index]\n        image = transform_image(f)\n        target = torch.Tensor(self.df.cancer.tolist())[index]\n        image = torch.Tensor(image)\n        send = {'image': image, 'target': target}\n        return send","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:43.378505Z","iopub.execute_input":"2023-02-14T05:39:43.378931Z","iopub.status.idle":"2023-02-14T05:39:43.394064Z","shell.execute_reply.started":"2023-02-14T05:39:43.378880Z","shell.execute_reply":"2023-02-14T05:39:43.393053Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Custom Pytorch Model","metadata":{}},{"cell_type":"code","source":"class Model_from_timm(nn.Module):\n    def __init__(self, model_name:str, pretrained:bool=True):\n        super().__init__()\n        self.backbone = timm.create_model(model_name, pretrained=pretrained, in_chans=1, num_classes=0)\n        self.in_features = self.backbone.num_features\n        \n        self.head = nn.Sequential(\n            nn.Linear(self.in_features, 100),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(100, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        h = self.backbone(x)\n        y = self.head(h)\n        return y","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:43.395702Z","iopub.execute_input":"2023-02-14T05:39:43.396088Z","iopub.status.idle":"2023-02-14T05:39:43.407104Z","shell.execute_reply.started":"2023-02-14T05:39:43.396053Z","shell.execute_reply":"2023-02-14T05:39:43.406157Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## other functions","metadata":{}},{"cell_type":"code","source":"def balance_df(df):\n    one_x = df[df['cancer']==1]\n    zero_x = df[df['cancer']==0]\n    zero_x_2 = zero_x.sample(one_x.shape[0], random_state=config.seed)\n    new_df = pd.concat([one_x, zero_x_2])\n    new_df = new_df.reset_index()\n    return new_df\n\ndef convert(lists):\n    tmp = []\n    for i in range(len(lists)):\n        x = lists[i].tolist()\n        for j in range(len(x)):\n            tmp.append(x[j][0])\n    return tmp\n\ndef pfbeta(labels, predictions, beta = 1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:43.408401Z","iopub.execute_input":"2023-02-14T05:39:43.409327Z","iopub.status.idle":"2023-02-14T05:39:43.422461Z","shell.execute_reply.started":"2023-02-14T05:39:43.409288Z","shell.execute_reply":"2023-02-14T05:39:43.421546Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ntrain['filename'] = train.apply(lambda x: '/kaggle/input/rsna-breast-cancer-detection/train_images/'+str(x.patient_id)+'/'+str(x.image_id)+'.dcm', axis=1)\nnew_df = balance_df(train.copy())\ntrain, test = train_test_split(new_df, stratify=new_df.cancer, random_state=config.seed, test_size=0.2)\ndataset = TrainDataset(train)\ndataloader = DataLoader(dataset, batch_size=config.batch_size, drop_last=False, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:43.423798Z","iopub.execute_input":"2023-02-14T05:39:43.424748Z","iopub.status.idle":"2023-02-14T05:39:44.575103Z","shell.execute_reply.started":"2023-02-14T05:39:43.424713Z","shell.execute_reply":"2023-02-14T05:39:44.574124Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"def train_net(n_epochs, train_loader, net, optimizer, loss_fn, model_name, device='cpu'):\n    save_path = f'{model_name}_{datetime.datetime.now().strftime(\"%y%m%d\")}.pth'\n    earlystopping = EarlyStopping(verbose=True, path=save_path)\n    print(f'device=={device}')\n    print(f'model_name=={model_name}')\n    losses = []\n    net.to(device)\n    torch.cuda.manual_seed(config.seed)\n    \n    for epoch in range(n_epochs):\n        running_loss = 0\n        net.train()\n        print(f'epoch {epoch} start')\n        for index, data in enumerate(train_loader):\n            inputs, labels = data['image'], data['target']\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            inputs = inputs.unsqueeze(dim=1)\n            labels = labels.unsqueeze(dim=1)\n            \n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = loss_fn(outputs, labels)\n            print(f'index: {index}, loss: {loss}')\n            print(f'outputs: {outputs.tolist()[:3]}, labels: {labels.tolist()[:3]}')\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        losses.append( running_loss / index)\n        print(f'epoch, {epoch} : {running_loss/ index}')\n        \n        earlystopping((running_loss/index), net)\n        if earlystopping.early_stop:\n            print('Early Stop!!!!!')\n            break\n    return losses","metadata":{"execution":{"iopub.status.busy":"2023-02-14T05:39:44.576825Z","iopub.execute_input":"2023-02-14T05:39:44.577214Z","iopub.status.idle":"2023-02-14T05:39:44.587710Z","shell.execute_reply.started":"2023-02-14T05:39:44.577176Z","shell.execute_reply":"2023-02-14T05:39:44.586669Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nnet = Model_from_timm(config.model_name)\ncriterion = nn.BCELoss()\noptimizer = optim.AdamW(net.parameters())\n# optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:44:30.159197Z","iopub.execute_input":"2023-02-14T07:44:30.159729Z","iopub.status.idle":"2023-02-14T07:44:34.946692Z","shell.execute_reply.started":"2023-02-14T07:44:30.159688Z","shell.execute_reply":"2023-02-14T07:44:34.945664Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"losses = train_net(n_epochs=config.epochs, train_loader=dataloader, net=net,\n                   optimizer=optimizer, loss_fn=criterion,\n                   model_name=config.model_name, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:44:35.777527Z","iopub.execute_input":"2023-02-14T07:44:35.778667Z","iopub.status.idle":"2023-02-14T07:55:41.651638Z","shell.execute_reply.started":"2023-02-14T07:44:35.778620Z","shell.execute_reply":"2023-02-14T07:55:41.649901Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"device==cuda\nmodel_name==vgg11\nepoch 0 start\nindex: 0, loss: 0.7068426609039307\noutputs: [[0.5438529253005981], [0.5222128033638], [0.49238890409469604]], labels: [[1.0], [1.0], [0.0]]\nindex: 1, loss: 3.3973629474639893\noutputs: [[0.002164656762033701], [0.006180374417454004], [0.014860199764370918]], labels: [[1.0], [0.0], [0.0]]\nindex: 2, loss: 0.6974515914916992\noutputs: [[0.5021376609802246], [0.5225943922996521], [0.5185756683349609]], labels: [[0.0], [0.0], [0.0]]\nindex: 3, loss: 0.763258695602417\noutputs: [[0.3309766352176666], [0.2525508403778076], [0.4333162009716034]], labels: [[1.0], [1.0], [1.0]]\nindex: 4, loss: 0.7074992656707764\noutputs: [[0.5832001566886902], [0.5465620160102844], [0.5402883291244507]], labels: [[0.0], [1.0], [1.0]]\nindex: 5, loss: 0.7048647403717041\noutputs: [[0.48436132073402405], [0.4937305152416229], [0.45168793201446533]], labels: [[0.0], [1.0], [1.0]]\nindex: 6, loss: 0.7059527635574341\noutputs: [[0.4917164444923401], [0.4981887638568878], [0.4875020682811737]], labels: [[0.0], [1.0], [1.0]]\nindex: 7, loss: 0.703829824924469\noutputs: [[0.541325569152832], [0.5670562982559204], [0.5219616293907166]], labels: [[0.0], [0.0], [1.0]]\nindex: 8, loss: 0.7106281518936157\noutputs: [[0.70414137840271], [0.6716645956039429], [0.6809040307998657]], labels: [[1.0], [1.0], [0.0]]\nindex: 9, loss: 0.6952297687530518\noutputs: [[0.47218120098114014], [0.5070891976356506], [0.4806777238845825]], labels: [[0.0], [1.0], [1.0]]\nindex: 10, loss: 1.242725133895874\noutputs: [[0.08326714485883713], [0.037650417536497116], [0.20027579367160797]], labels: [[0.0], [1.0], [1.0]]\nindex: 11, loss: 0.6917215585708618\noutputs: [[0.5183505415916443], [0.5511269569396973], [0.5556762218475342]], labels: [[1.0], [1.0], [1.0]]\nindex: 12, loss: 0.7090891599655151\noutputs: [[0.560554563999176], [0.4989224076271057], [0.5610305666923523]], labels: [[0.0], [1.0], [1.0]]\nindex: 13, loss: 0.6962842345237732\noutputs: [[0.5183417797088623], [0.5511394739151001], [0.5916256308555603]], labels: [[0.0], [0.0], [1.0]]\nindex: 14, loss: 0.7030618190765381\noutputs: [[0.5237392783164978], [0.5654774904251099], [0.5852293968200684]], labels: [[1.0], [1.0], [1.0]]\nindex: 15, loss: 0.7045527100563049\noutputs: [[0.5625693798065186], [0.5438297986984253], [0.5039637088775635]], labels: [[0.0], [1.0], [1.0]]\nindex: 16, loss: 0.680633544921875\noutputs: [[0.4748304784297943], [0.554307758808136], [0.490753710269928]], labels: [[0.0], [1.0], [1.0]]\nindex: 17, loss: 0.6953437328338623\noutputs: [[0.5372805595397949], [0.5431147217750549], [0.527442216873169]], labels: [[1.0], [1.0], [1.0]]\nindex: 18, loss: 0.7969553470611572\noutputs: [[0.6392698884010315], [0.49158725142478943], [0.6316105723381042]], labels: [[0.0], [0.0], [1.0]]\nindex: 19, loss: 0.6930480003356934\noutputs: [[0.5284265279769897], [0.5075047016143799], [0.5096887350082397]], labels: [[0.0], [1.0], [1.0]]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2769/784093500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m losses = train_net(n_epochs=config.epochs, train_loader=dataloader, net=net,\n\u001b[1;32m      2\u001b[0m                    \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                    model_name=config.model_name, device=device)\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_2769/670812158.py\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(n_epochs, train_loader, net, optimizer, loss_fn, model_name, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch {epoch} start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_2769/1034130749.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_2769/53282458.py\u001b[0m in \u001b[0;36mtransform_image\u001b[0;34m(paths, side, size, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdicom_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicom_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdicom_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhotometricInterpretation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MONOCHROME1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"TEST_MODEL_PATH = '/kaggle/working/vgg11_230214.pth'\n\ntest_dataset = TrainDataset(test)\ntest_dataloader = DataLoader(test_dataset, batch_size=32)\nmodel = Model_from_timm(config.model_name, pretrained=False)\nmodel.load_state_dict(torch.load(TEST_MODEL_PATH))\n\ndef test_net(dataloader, model, device):\n    model = model.eval()\n    preds_lis = []\n    labels_lis = []\n    model.to(device)\n    for i, data in enumerate(dataloader):\n        with torch.no_grad():\n            inputs, labels = data['image'], data['target']\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            inputs = inputs.unsqueeze(dim=1)\n            labels = labels.unsqueeze(dim=1)\n            inputs.to(device)\n            \n            output = model(inputs)\n            preds_lis.append(output)\n            labels_lis.append(labels)\n    return preds_lis, labels_lis\n\npreds, labels = test_net(test_dataloader, model, device)\n\npreds = convert(preds)\nlabels = convert(labels)\n\nprint(f'pf1:{pfbeta(labels, preds)}')","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:34:31.669872Z","iopub.execute_input":"2023-02-14T07:34:31.670621Z","iopub.status.idle":"2023-02-14T07:43:17.076374Z","shell.execute_reply.started":"2023-02-14T07:34:31.670574Z","shell.execute_reply":"2023-02-14T07:43:17.073972Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"pf1:0.5014033879219387\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}