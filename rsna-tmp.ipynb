{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TMP notebook\ncompetition : RSNA Screening Mammography Breast Cancer Detection  \nurl : https://www.kaggle.com/competitions/rsna-breast-cancer-detection","metadata":{}},{"cell_type":"markdown","source":"# 2023/1/22\nテーブルデータのみのlightgbmでどれくらい精度出るか検証  \n* 交差検証なし、パラメータチューニングなし\n\n## 結果\n* LB - 0.04","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import lightgbm as lgb\n# from sklearn.metrics import f1_score\n# from sklearn.model_selection import train_test_split\n# import warnings\n# warnings.simplefilter('ignore')\n\n# def pre_view(df):\n#     if 'view' in df.columns.tolist():\n#         df['view'] = df['view'].apply(lambda x: x if x=='CC' or x=='MLO' else 'others')\n#     else:\n#         pass\n#     return df\n\n# train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n# test = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n# submit = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/sample_submission.csv')\n\n# column = ['laterality', 'view', 'age', 'implant', 'cancer']\n# new_train = train[column]\n# new_train = new_train.dropna()\n# new_train = pre_view(new_train)\n# new_train_dum = pd.get_dummies(new_train)\n# train_cancer = new_train_dum[new_train_dum.cancer==1]\n# train_no_cancer = new_train_dum[new_train_dum.cancer==0]\n# tmp = train_no_cancer.sample(n=1158, random_state=0)\n# concat_train = pd.concat([train_cancer, tmp])\n\n# concat_train = concat_train.reset_index()\n# X = concat_train.drop(columns=['cancer'])\n# y = concat_train[['cancer']]\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n# # X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0, stratify=y_test)\n\n# model = lgb.LGBMClassifier(random_state=0)\n# model.fit(X_train, y_train)\n# pred = model.predict(X_test)\n# print(f1_score(y_test, pred))\n\n# tmp = test[['laterality', 'view', 'age', 'implant']]\n# tmp = pre_view(tmp)\n# tmp_ = pd.concat([new_train, tmp])\n# tmp_dum = pd.get_dummies(tmp_)\n# tmp_dum = tmp_dum.reset_index()\n# test_X = tmp_dum.iloc[new_train.shape[0]:]\n# test_X = test_X.drop(columns=['cancer'])\n# test_pred = model.predict(test_X)\n# print(test_pred)\n# test_copy = test.copy()\n# test_copy['pred'] = test_pred\n# tmp = test_copy.groupby('prediction_id')['pred'].mean()\n# sub = pd.DataFrame(data={'prediction_id': tmp.index.tolist(), 'cancer': tmp.values.tolist()})\n# display(sub)\n# sub.to_csv('submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T10:37:03.542591Z","iopub.execute_input":"2023-01-22T10:37:03.543201Z","iopub.status.idle":"2023-01-22T10:37:03.856648Z","shell.execute_reply.started":"2023-01-22T10:37:03.543164Z","shell.execute_reply":"2023-01-22T10:37:03.855913Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/28\n画像について調べる","metadata":{}},{"cell_type":"code","source":"# !pip install -qU python-gdcm pydicom pylibjpeg\n# !pip install japanize-matplotlib\n!pip install /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nimport dicomsdl\nimport cv2\nimport os\nimport copy\nimport random\nimport pydicom\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# import japanize_matplotlib\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 50)\n\nfrom torch.utils.data import Dataset, DataLoader\n#　使い方\n# https://pystyle.info/pytorch-how-to-create-custom-dataset-class/\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:29:47.452923Z","iopub.execute_input":"2023-01-28T08:29:47.453296Z","iopub.status.idle":"2023-01-28T08:30:17.074436Z","shell.execute_reply.started":"2023-01-28T08:29:47.453263Z","shell.execute_reply":"2023-01-28T08:30:17.073165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:30:17.077259Z","iopub.execute_input":"2023-01-28T08:30:17.077558Z","iopub.status.idle":"2023-01-28T08:30:17.817632Z","shell.execute_reply.started":"2023-01-28T08:30:17.077530Z","shell.execute_reply":"2023-01-28T08:30:17.816653Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_image = '/kaggle/input/rsna-breast-cancer-detection/train_images/10011/1031443799.dcm'\n# im_data = pydicom.dcmread(sample_image)\n# # print(im_data)\n# data = im_data.pixel_array\n# data.shape\n# plt.imshow(im_data.pixel_array)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T06:38:01.754762Z","iopub.execute_input":"2023-01-28T06:38:01.755274Z","iopub.status.idle":"2023-01-28T06:38:01.761272Z","shell.execute_reply.started":"2023-01-28T06:38:01.755225Z","shell.execute_reply":"2023-01-28T06:38:01.760006Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(15, 10))\n# axs = axs.flatten()\n# for i in range(8):\n#     if i <= 3:\n#         MONO = 'MONOCHROME1'\n#     else:\n#         MONO = 'MONOCHROME2'\n#     ran = random.randint(0,9000)\n#     tmp = dicom_df[dicom_df.PhotometricInterpretation == MONO].iloc[ran]\n#     p_id = tmp.patient_id\n#     i_id = tmp.image_id\n#     pas = f'/kaggle/input/rsna-breast-cancer-detection/train_images/{p_id}/{i_id}.dcm'\n#     im_data = pydicom.dcmread(pas)\n#     axs[i].imshow(im_data.pixel_array)\n#     axs[i].axis('off')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T02:14:48.473237Z","iopub.execute_input":"2023-01-28T02:14:48.473956Z","iopub.status.idle":"2023-01-28T02:15:07.620024Z","shell.execute_reply.started":"2023-01-28T02:14:48.473918Z","shell.execute_reply":"2023-01-28T02:15:07.618835Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:48:44.274589Z","iopub.execute_input":"2023-01-28T08:48:44.274990Z","iopub.status.idle":"2023-01-28T08:48:44.286369Z","shell.execute_reply.started":"2023-01-28T08:48:44.274954Z","shell.execute_reply":"2023-01-28T08:48:44.285204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = [custom_train.filename[1]]\n# data = transform_image(paths)\n# plt.imshow(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:31.025795Z","iopub.execute_input":"2023-01-28T09:56:31.026741Z","iopub.status.idle":"2023-01-28T09:56:31.031256Z","shell.execute_reply.started":"2023-01-28T09:56:31.026703Z","shell.execute_reply":"2023-01-28T09:56:31.030229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path入力\n# 余計な余白除去と左向き揃えをした画像が出力される\n# リサイズ済み\nclass Image_preprocessor:\n    def __init__(self,side='left', size=512):\n        self.side = side\n        self.size = size\n        \n    def preprocess(self, paths):\n        images = []\n        for image_path in paths:\n            image = self.read_xray(image_path)\n            image = self.crop_image(image)\n            img_side = self.determine_side(image)\n            if img_side != self.side: \n                image = cv2.flip(image, 1)\n            image = self.img2roi(image)\n            image = cv2.resize(image, (self.size, self.size))\n            images.append(image)\n        return images\n    \n    \n    def read_xray(self, path, fix_monochrome = True):\n        dicom = dicomsdl.open(path)\n        data = dicom.pixelData(storedvalue=False)  # storedvalue = True for int16 return otherwise float32\n        data = data - np.min(data)\n        data = data / np.max(data)\n        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            data = 1.0 - data\n        return data\n\n    def crop_image(self, image):\n        # 画像によっては不要な枠があるので、取り除く\n        image = image[5:-5, 5:-5]\n        return image\n    \n    def img2roi(self, image):\n        output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n        stats = output[2] # left, top, width, height, area_size\n\n        idx = stats[1:, 4].argmax() + 1\n        x1, y1, w, h = stats[idx][:4]\n        x2 = x1 + w\n        y2 = y1 + h\n\n        image_fit = image[y1: y2, x1: x2]\n\n        return image_fit\n    \n    def determine_side(self, img, threshold = 0.05):\n        \"\"\"\n        img: input image\n        threshold: for binirizing image, should be 5\n        Side is determined simply by finding more white side of the image.\n        \"\"\"\n\n        if img.dtype == 'float32':\n            ret, thresh = cv2.threshold(img, threshold, 1, 0)\n#         else:\n#             img = (255*img).astype(dtype = 'float32')\n#             ret, thresh = cv2.threshold(img, threshold, 1, 0)\n\n        width = img.shape[1]\n        # take all columns up to half image (in width), sumarize them and compare with other half\n        if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n            return 'left'\n        else:\n            return 'right'","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:06:32.142432Z","iopub.execute_input":"2023-01-28T08:06:32.143038Z","iopub.status.idle":"2023-01-28T08:06:32.157763Z","shell.execute_reply.started":"2023-01-28T08:06:32.142985Z","shell.execute_reply":"2023-01-28T08:06:32.156765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = ['/kaggle/input/rsna-breast-cancer-detection/train_images/10006/1864590858.dcm', '/kaggle/input/rsna-breast-cancer-detection/train_images/10006/462822612.dcm']\n# x = Image_preprocessor()\n# data = x.preprocess(paths)\n# plt.imshow(data[1])\n# plt.show()\n# print(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:38.337426Z","iopub.execute_input":"2023-01-28T09:56:38.337790Z","iopub.status.idle":"2023-01-28T09:56:38.342364Z","shell.execute_reply.started":"2023-01-28T09:56:38.337759Z","shell.execute_reply":"2023-01-28T09:56:38.341283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = train.copy()\n# root_dir = '/kaggle/input/rsna-breast-cancer-detection/train_images'\n# df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n# df['site_id_1'] = df['site_id_2'] = 0\n# df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n# df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n# for i in range(df.shape[0]):\n#     tmp = df.iloc[i]\n#     s_value = tmp['site_id']\n#     v_value = tmp['view']\n#     m_value = tmp['machine_id']\n#     s_name = f'site_id_{s_value}'\n#     v_name = f'view_{v_value}'\n#     m_name = f'machine_{m_value}'\n#     df.loc[i, s_name] = 1\n#     df.loc[i, v_name] = 1\n#     df.loc[i, m_name] = 1\n# train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'],axis=1)\n# train_input['age'].fillna(60, inplace=True)\n# train_input.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:13:13.541126Z","iopub.execute_input":"2023-01-28T07:13:13.541807Z","iopub.status.idle":"2023-01-28T07:13:13.546872Z","shell.execute_reply.started":"2023-01-28T07:13:13.541771Z","shell.execute_reply":"2023-01-28T07:13:13.545705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_table(df, root_dir='/kaggle/input/rsna-breast-cancer-detection/train_images'):\n    df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n    df['site_id_1'] = df['site_id_2'] = 0\n    df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n    df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n    for i in range(df.shape[0]):\n        tmp = df.iloc[i]\n        s_value = tmp['site_id']\n        v_value = tmp['view']\n        m_value = tmp['machine_id']\n        s_name = f'site_id_{s_value}'\n        v_name = f'view_{v_value}'\n        m_name = f'machine_{m_value}'\n        df.loc[i, s_name] = 1\n        df.loc[i, v_name] = 1\n        df.loc[i, m_name] = 1\n    train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n    train_input['age'].fillna(60, inplace=True)\n    return train_input\n\n# t = Image_preprocessor()\nclass RSNADataset(Dataset):\n    def __init__(self, df, root_dir, is_preprocess=False, transform=False):\n        self.table = df\n        self.root_dir = root_dir\n        self.is_preprocess = is_preprocess\n        self.transform = transform\n        \n    def __len__(self):\n        return self.table.shape[0]\n    \n    def __getitem__(self, idx):\n        df_tmp = self.table\n        if self.is_preprocess:\n            train_dataset = pre_table(df_tmp, self.root_dir)\n        else:\n            train_dataset = self.table.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n        image_name = df_tmp.filename.tolist()[idx]\n        image = t.preprocess(image_name)\n        image = torch.Tensor(image)\n        target = torch.Tensor(df_tmp['cancer'].tolist())[idx]\n        sample = {'image': image,'answer':target}\n        return sample\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:00:13.394164Z","iopub.execute_input":"2023-01-28T08:00:13.394596Z","iopub.status.idle":"2023-01-28T08:00:13.409452Z","shell.execute_reply.started":"2023-01-28T08:00:13.394561Z","shell.execute_reply":"2023-01-28T08:00:13.408188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# csv_file = '/kaggle/input/rsnacustomtrain/custom_train.csv'\n# root_dir = '/kaggle/inpu/rsna-breast-cancer-detection/train_images'\n# dataset = RSNADataset(custom_train, root_dir)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:48:19.192882Z","iopub.execute_input":"2023-01-28T07:48:19.193491Z","iopub.status.idle":"2023-01-28T07:48:19.202365Z","shell.execute_reply.started":"2023-01-28T07:48:19.193446Z","shell.execute_reply":"2023-01-28T07:48:19.201182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\nimport numpy as np\nimport pandas as pd\nfrom torch import optim\nimport torch\nCUDA_LAUNCH_BLOCKING=1\nfrom torchvision import models\nimport torch.nn as nn\nimport os\nfrom skimage import io, transform\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport skimage\nfrom skimage.color import rgb2gray, gray2rgb\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:51:06.597093Z","iopub.execute_input":"2023-01-28T08:51:06.597467Z","iopub.status.idle":"2023-01-28T08:51:07.251636Z","shell.execute_reply.started":"2023-01-28T08:51:06.597439Z","shell.execute_reply":"2023-01-28T08:51:07.250660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        paths = self.df.filename.tolist()[idx]\n        data = transform_image(paths)\n        data = torch.Tensor(data)\n        target = torch.Tensor(self.df['cancer'].tolist())[idx]\n        sample = {'data': data, 'target': target}\n        return sample\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:54.644018Z","iopub.execute_input":"2023-01-28T09:48:54.644482Z","iopub.status.idle":"2023-01-28T09:48:54.658893Z","shell.execute_reply.started":"2023-01-28T09:48:54.644444Z","shell.execute_reply":"2023-01-28T09:48:54.657585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset = TrainDataset(custom_train)\n# dataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:51:38.538837Z","iopub.execute_input":"2023-01-28T09:51:38.539728Z","iopub.status.idle":"2023-01-28T09:51:38.545690Z","shell.execute_reply.started":"2023-01-28T09:51:38.539681Z","shell.execute_reply":"2023-01-28T09:51:38.544571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for batch in dataloader:\n#     print(batch['data'].shape)\n#     print(batch['target'])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:18.226761Z","iopub.execute_input":"2023-01-28T09:54:18.227177Z","iopub.status.idle":"2023-01-28T09:54:18.232252Z","shell.execute_reply.started":"2023-01-28T09:54:18.227141Z","shell.execute_reply":"2023-01-28T09:54:18.230845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nfrom pprint import pprint\npprint(timm.list_models(pretrained = True))","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.272794Z","iopub.execute_input":"2023-01-28T09:48:58.273798Z","iopub.status.idle":"2023-01-28T09:48:58.292477Z","shell.execute_reply.started":"2023-01-28T09:48:58.273758Z","shell.execute_reply":"2023-01-28T09:48:58.291411Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tmp_model = timm.create_model(model_name='resnest26d')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.308153Z","iopub.execute_input":"2023-01-28T09:48:58.308720Z","iopub.status.idle":"2023-01-28T09:48:58.583531Z","shell.execute_reply.started":"2023-01-28T09:48:58.308682Z","shell.execute_reply":"2023-01-28T09:48:58.582462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.effnet = timm.create_model(model_name = \"tf_efficientnet_b0\", pretrained = False)\n        n_features = self.effnet.classifier.in_features\n        self.effnet.classifier = nn.Linear(n_features, 1)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.effnet(x)\n        return x\nmodel = Effnet()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.585488Z","iopub.execute_input":"2023-01-28T09:48:58.585864Z","iopub.status.idle":"2023-01-28T09:48:58.704828Z","shell.execute_reply.started":"2023-01-28T09:48:58.585826Z","shell.execute_reply":"2023-01-28T09:48:58.703858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(DEVICE)\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.706437Z","iopub.execute_input":"2023-01-28T09:48:58.706807Z","iopub.status.idle":"2023-01-28T09:48:58.728464Z","shell.execute_reply.started":"2023-01-28T09:48:58.706772Z","shell.execute_reply":"2023-01-28T09:48:58.727493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters())\n","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.730716Z","iopub.execute_input":"2023-01-28T09:48:58.731547Z","iopub.status.idle":"2023-01-28T09:48:58.737794Z","shell.execute_reply.started":"2023-01-28T09:48:58.731521Z","shell.execute_reply":"2023-01-28T09:48:58.736692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TrainDataset(custom_train)\ndataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.739381Z","iopub.execute_input":"2023-01-28T09:48:58.740007Z","iopub.status.idle":"2023-01-28T09:48:58.746471Z","shell.execute_reply.started":"2023-01-28T09:48:58.739972Z","shell.execute_reply":"2023-01-28T09:48:58.745576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.train()\n# for data in dataloader:\n#     optimizer.zero_grad()\n#     X = data['data'].float().to(DEVICE)\n#     y = data['target'].float().to(DEVICE)\n#     pred = model(X)\n#     loss = criterion(pred, y)\n#     loss.backward()\n#     optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:04.182053Z","iopub.execute_input":"2023-01-28T09:54:04.182435Z","iopub.status.idle":"2023-01-28T09:54:04.188058Z","shell.execute_reply.started":"2023-01-28T09:54:04.182404Z","shell.execute_reply":"2023-01-28T09:54:04.186985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/29","metadata":{}},{"cell_type":"code","source":"!pip install -U pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg pydicom python-gdcm","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:26.356413Z","iopub.execute_input":"2023-01-30T06:19:26.356856Z","iopub.status.idle":"2023-01-30T06:19:37.417529Z","shell.execute_reply.started":"2023-01-30T06:19:26.356766Z","shell.execute_reply":"2023-01-30T06:19:37.416199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install python-gdcm -q\n!pip install pylibjpeg -q","metadata":{"execution":{"iopub.status.busy":"2023-02-09T06:47:30.492625Z","iopub.execute_input":"2023-02-09T06:47:30.493154Z","iopub.status.idle":"2023-02-09T06:47:49.795934Z","shell.execute_reply.started":"2023-02-09T06:47:30.493113Z","shell.execute_reply":"2023-02-09T06:47:49.794711Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport pydicom\nimport gdcm\nimport pylibjpeg\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-02-09T06:47:52.912070Z","iopub.execute_input":"2023-02-09T06:47:52.912456Z","iopub.status.idle":"2023-02-09T06:47:52.918712Z","shell.execute_reply.started":"2023-02-09T06:47:52.912418Z","shell.execute_reply":"2023-02-09T06:47:52.917696Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:39.466131Z","iopub.execute_input":"2023-01-30T06:19:39.466795Z","iopub.status.idle":"2023-01-30T06:19:40.303771Z","shell.execute_reply.started":"2023-01-30T06:19:39.466755Z","shell.execute_reply":"2023-01-30T06:19:40.302604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:45.876274Z","iopub.execute_input":"2023-01-30T06:19:45.876763Z","iopub.status.idle":"2023-01-30T06:19:45.889483Z","shell.execute_reply.started":"2023-01-30T06:19:45.876717Z","shell.execute_reply":"2023-01-30T06:19:45.888204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        f = self.df.filename.tolist()[index]\n        image = transform_image(f)\n        target = torch.Tensor(self.df.cancer.tolist())[index]\n        image = torch.Tensor(image)\n#         target = target.unsqueeze(dim=-1)\n#         image = image.unsqueeze(dim=0)\n        send = {'image': image, 'target': target}\n        return send","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:46.033098Z","iopub.execute_input":"2023-01-30T06:19:46.033583Z","iopub.status.idle":"2023-01-30T06:19:46.042207Z","shell.execute_reply.started":"2023-01-30T06:19:46.033534Z","shell.execute_reply":"2023-01-30T06:19:46.041144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_dataset = TrainDataset(custom_train)\ntmp_dataloader = DataLoader(tmp_dataset, batch_size=30)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:26.084944Z","iopub.execute_input":"2023-01-30T06:32:26.086176Z","iopub.status.idle":"2023-01-30T06:32:26.091186Z","shell.execute_reply.started":"2023-01-30T06:32:26.086131Z","shell.execute_reply":"2023-01-30T06:32:26.089587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.pool = nn.MaxPool2d(2, stride=2)\n        \n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n        \n        self.fc1 = nn.Linear(32*253*253, 100)\n        self.fc2 = nn.Linear(100, 50)\n        self.fc3 = nn.Linear(50, 10)\n        self.fc4 = nn.Linear(10, 1)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = x.view(-1, 32*253*253)\n        x = self.fc1(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.fc4(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:34.216861Z","iopub.execute_input":"2023-01-30T06:32:34.217616Z","iopub.status.idle":"2023-01-30T06:32:34.229746Z","shell.execute_reply.started":"2023-01-30T06:32:34.217576Z","shell.execute_reply":"2023-01-30T06:32:34.228786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# device = torch.device(\"cuda:0\")\nnet = Net()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:39.287764Z","iopub.execute_input":"2023-01-30T06:32:39.288790Z","iopub.status.idle":"2023-01-30T06:32:41.368496Z","shell.execute_reply.started":"2023-01-30T06:32:39.288749Z","shell.execute_reply":"2023-01-30T06:32:41.367479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):\n    print(f'epoch:{epoch}')\n    for i, data in enumerate(tmp_dataloader):\n        print(f'i:{i}')\n        if i==20:\n            break\n        inputs = data['image']\n        labels = data['target']\n        inputs, labels = inputs.to(device), labels.to(device)\n        inputs = inputs.unsqueeze(dim=1)\n        labels = labels.unsqueeze(dim=1)\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        print(f'train_loss:{loss}')\n\n#     for data in tmp_dataloader:\n#         inputs = data['image']\n#         inputs = inputs.unsqueeze(dim=1)\n#         labels = data['target']\n#         labels = labels.unsqueeze(dim=1)\n#         inputs, labels = inputs.to(device), labels.to(device)\n#         optimizer.zero_grad()\n#         outputs = net(inputs)\n#         loss = criterion(outputs, labels)\n#         print(f'test_loss:{loss}')\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:33:00.521541Z","iopub.execute_input":"2023-01-30T06:33:00.522006Z","iopub.status.idle":"2023-01-30T06:54:05.365556Z","shell.execute_reply.started":"2023-01-30T06:33:00.521967Z","shell.execute_reply":"2023-01-30T06:54:05.363845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2023/2/1","metadata":{}},{"cell_type":"markdown","source":"htmlをおしゃれにするやつを見つけたからやってみた","metadata":{}},{"cell_type":"code","source":"!wget http://bit.ly/3ZLyF82 -O CSS.css -q\n    \nfrom IPython.core.display import HTML\nwith open('./CSS.css', 'r') as file:\n    custom_css = file.read()\n\nHTML(custom_css)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:21:58.914929Z","iopub.execute_input":"2023-02-01T10:21:58.915271Z","iopub.status.idle":"2023-02-01T10:22:00.675000Z","shell.execute_reply.started":"2023-02-01T10:21:58.915187Z","shell.execute_reply":"2023-02-01T10:22:00.673669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:23:26.201738Z","iopub.execute_input":"2023-02-01T10:23:26.202209Z","iopub.status.idle":"2023-02-01T10:23:26.308711Z","shell.execute_reply.started":"2023-02-01T10:23:26.202175Z","shell.execute_reply":"2023-02-01T10:23:26.307544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train.age)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:24:40.803009Z","iopub.execute_input":"2023-02-01T10:24:40.803399Z","iopub.status.idle":"2023-02-01T10:24:41.063581Z","shell.execute_reply.started":"2023-02-01T10:24:40.803365Z","shell.execute_reply":"2023-02-01T10:24:41.062537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\nplt.hist(train.age)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:26:06.727444Z","iopub.execute_input":"2023-02-01T10:26:06.728184Z","iopub.status.idle":"2023-02-01T10:26:07.015763Z","shell.execute_reply.started":"2023-02-01T10:26:06.728147Z","shell.execute_reply":"2023-02-01T10:26:07.014678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2023/2/9","metadata":{}},{"cell_type":"code","source":"!pip install -U pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg pydicom python-gdcm","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:21:50.509699Z","iopub.execute_input":"2023-02-09T08:21:50.510015Z","iopub.status.idle":"2023-02-09T08:22:04.491337Z","shell.execute_reply.started":"2023-02-09T08:21:50.509945Z","shell.execute_reply":"2023-02-09T08:22:04.490223Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pylibjpeg\n  Downloading pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\nCollecting pylibjpeg-openjpeg\n  Downloading pylibjpeg_openjpeg-1.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting pylibjpeg-libjpeg\n  Downloading pylibjpeg_libjpeg-1.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\nCollecting python-gdcm\n  Downloading python_gdcm-3.0.21-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\nInstalling collected packages: python-gdcm, pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg\nSuccessfully installed pylibjpeg-1.4.0 pylibjpeg-libjpeg-1.3.3 pylibjpeg-openjpeg-1.3.1 python-gdcm-3.0.21\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport PIL\nimport pydicom\nimport gdcm\nimport pylibjpeg\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:22:06.629340Z","iopub.execute_input":"2023-02-09T08:22:06.629745Z","iopub.status.idle":"2023-02-09T08:22:09.070353Z","shell.execute_reply.started":"2023-02-09T08:22:06.629708Z","shell.execute_reply":"2023-02-09T08:22:09.069453Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:22:10.773824Z","iopub.execute_input":"2023-02-09T08:22:10.774984Z","iopub.status.idle":"2023-02-09T08:22:11.532741Z","shell.execute_reply.started":"2023-02-09T08:22:10.774939Z","shell.execute_reply":"2023-02-09T08:22:11.531782Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:22:13.280877Z","iopub.execute_input":"2023-02-09T08:22:13.281675Z","iopub.status.idle":"2023-02-09T08:22:13.292517Z","shell.execute_reply.started":"2023-02-09T08:22:13.281636Z","shell.execute_reply":"2023-02-09T08:22:13.291601Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        f = self.df.filename.tolist()[index]\n        image = transform_image(f)\n        target = torch.Tensor(self.df.cancer.tolist())[index]\n        image = torch.Tensor(image)\n#         target = target.unsqueeze(dim=-1)\n#         image = image.unsqueeze(dim=0)\n        send = {'image': image, 'target': target}\n        return send","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:22:14.675746Z","iopub.execute_input":"2023-02-09T08:22:14.676100Z","iopub.status.idle":"2023-02-09T08:22:14.690009Z","shell.execute_reply.started":"2023-02-09T08:22:14.676069Z","shell.execute_reply":"2023-02-09T08:22:14.688433Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"one_x = custom_train[custom_train['cancer']==1]\nzero_x = custom_train[custom_train['cancer']==0]\nprint(one_x.shape)\nprint(zero_x.shape)\nzero_x_2 = zero_x.sample(one_x.shape[0], random_state=0)\nprint(zero_x_2.shape)\nnew_df = pd.concat([one_x, zero_x_2])\nprint(new_df.shape)\nnew_df = new_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:22:15.996683Z","iopub.execute_input":"2023-02-09T08:22:15.997077Z","iopub.status.idle":"2023-02-09T08:22:16.030410Z","shell.execute_reply.started":"2023-02-09T08:22:15.997047Z","shell.execute_reply":"2023-02-09T08:22:16.029353Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(1158, 34)\n(53548, 34)\n(1158, 34)\n(2316, 34)\n","output_type":"stream"}]},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):\n        self.patience = patience #設定ストップカウンタ\n        self.verbose = verbose #表示の有無\n        self.counter = 0 #現在のカウンタ値\n        self.best_score = None #ベストスコア\n        self.early_stop = False #ストップフラグ\n        self.val_loss_min = np.Inf # 前回のベストスコア記憶用\n        self.path = path #ベストモデルの格納パス\n    \n    def __call__(self, val_loss, model):\n        score = -val_loss\n        \n        if self.best_score is None:\n            self.best_score = score\n            self.checkpoint(val_loss, model)\n        elif score < self.best_score:\n            self.counter += 1\n            if self.verbose:\n                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.checkpoint(val_loss, model)\n            self.counter = 0\n    \n    def checkpoint(self, val_loss, model):\n        if self.verbose:\n            print(f'validation loss decreased({self.val_loss_min:.6f} ---> {val_loss:.6f}). saving model....')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.pool = nn.MaxPool2d(2, stride=2)\n        \n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n        \n        self.fc1 = nn.Linear(32*253*253, 100)\n        self.fc2 = nn.Linear(100, 50)\n        self.fc3 = nn.Linear(50, 10)\n        self.fc4 = nn.Linear(10, 1)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = x.view(-1, 32*253*253)\n        x = self.fc1(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.fc4(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:22:17.813031Z","iopub.execute_input":"2023-02-09T08:22:17.813970Z","iopub.status.idle":"2023-02-09T08:22:17.828836Z","shell.execute_reply.started":"2023-02-09T08:22:17.813922Z","shell.execute_reply":"2023-02-09T08:22:17.827623Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_net(n_epochs, train_loader, net, optimizer, loss_fn, device='cpu'):\n    earlystopping = EarlyStopping(verbose=True)\n    print(f'device=={device}')\n    losses = []\n    net.to(device)\n    \n    for epoch in range(n_epochs):\n        running_loss = 0\n        net.train()\n        print(f'epoch {epoch} start')\n        for index, data in enumerate(train_loader):\n            inputs, labels = data['image'], data['target']\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            inputs = inputs.unsqueeze(dim=1)\n            labels = labels.unsqueeze(dim=1)\n            \n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = loss_fn(outputs, labels)\n            print(f'''\n                        index: {index}\n                        outputs: {outputs[:3]}, \n                        labels: {labels[:3]},\n                        loss: {loss}''')\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        losses.append( running_loss / index)\n        print(f'epoch, {epoch} : {running_loss/ index}')\n        \n        earlystopping((running_loss/index), net)\n        if earlystopping.early_stop:\n            print('Early Stop!!!!!')\n            break\n    return losses","metadata":{"execution":{"iopub.status.busy":"2023-02-09T08:22:19.305243Z","iopub.execute_input":"2023-02-09T08:22:19.305667Z","iopub.status.idle":"2023-02-09T08:22:19.314861Z","shell.execute_reply.started":"2023-02-09T08:22:19.305631Z","shell.execute_reply":"2023-02-09T08:22:19.313879Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nnet = Net()\ncriterion = nn.BCELoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:16:11.605285Z","iopub.execute_input":"2023-02-09T09:16:11.606016Z","iopub.status.idle":"2023-02-09T09:16:13.469861Z","shell.execute_reply.started":"2023-02-09T09:16:11.605975Z","shell.execute_reply":"2023-02-09T09:16:13.468830Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(new_df, stratify=new_df.cancer, random_state=0, test_size=0.2)\ndataset = TrainDataset(train)\ndataloader = DataLoader(dataset, batch_size=128, num_workers=2, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:16:09.021531Z","iopub.execute_input":"2023-02-09T09:16:09.021919Z","iopub.status.idle":"2023-02-09T09:16:09.033461Z","shell.execute_reply.started":"2023-02-09T09:16:09.021885Z","shell.execute_reply":"2023-02-09T09:16:09.032590Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"losses = train_net(n_epochs=3, train_loader=dataloader,  net=net, optimizer=optimizer, loss_fn=criterion, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:16:20.152180Z","iopub.execute_input":"2023-02-09T09:16:20.152585Z","iopub.status.idle":"2023-02-09T09:20:23.395164Z","shell.execute_reply.started":"2023-02-09T09:16:20.152530Z","shell.execute_reply":"2023-02-09T09:20:23.393507Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"device==cuda\nepoch 0 start\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:104: operator(): block: [0,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/4195382954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/2133913037.py\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(n_epochs, train_loader, net, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'outputs: {outputs[:3]}, labels: {labels[:3]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'index:{index}, loss:{loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ipow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    407\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}