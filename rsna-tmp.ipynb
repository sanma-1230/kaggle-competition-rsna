{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TMP notebook\ncompetition : RSNA Screening Mammography Breast Cancer Detection  \nurl : https://www.kaggle.com/competitions/rsna-breast-cancer-detection","metadata":{}},{"cell_type":"markdown","source":"# 2023/1/22\nテーブルデータのみのlightgbmでどれくらい精度出るか検証  \n* 交差検証なし、パラメータチューニングなし\n\n## 結果\n* LB - 0.04","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import lightgbm as lgb\n# from sklearn.metrics import f1_score\n# from sklearn.model_selection import train_test_split\n# import warnings\n# warnings.simplefilter('ignore')\n\n# def pre_view(df):\n#     if 'view' in df.columns.tolist():\n#         df['view'] = df['view'].apply(lambda x: x if x=='CC' or x=='MLO' else 'others')\n#     else:\n#         pass\n#     return df\n\n# train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n# test = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n# submit = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/sample_submission.csv')\n\n# column = ['laterality', 'view', 'age', 'implant', 'cancer']\n# new_train = train[column]\n# new_train = new_train.dropna()\n# new_train = pre_view(new_train)\n# new_train_dum = pd.get_dummies(new_train)\n# train_cancer = new_train_dum[new_train_dum.cancer==1]\n# train_no_cancer = new_train_dum[new_train_dum.cancer==0]\n# tmp = train_no_cancer.sample(n=1158, random_state=0)\n# concat_train = pd.concat([train_cancer, tmp])\n\n# concat_train = concat_train.reset_index()\n# X = concat_train.drop(columns=['cancer'])\n# y = concat_train[['cancer']]\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n# # X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0, stratify=y_test)\n\n# model = lgb.LGBMClassifier(random_state=0)\n# model.fit(X_train, y_train)\n# pred = model.predict(X_test)\n# print(f1_score(y_test, pred))\n\n# tmp = test[['laterality', 'view', 'age', 'implant']]\n# tmp = pre_view(tmp)\n# tmp_ = pd.concat([new_train, tmp])\n# tmp_dum = pd.get_dummies(tmp_)\n# tmp_dum = tmp_dum.reset_index()\n# test_X = tmp_dum.iloc[new_train.shape[0]:]\n# test_X = test_X.drop(columns=['cancer'])\n# test_pred = model.predict(test_X)\n# print(test_pred)\n# test_copy = test.copy()\n# test_copy['pred'] = test_pred\n# tmp = test_copy.groupby('prediction_id')['pred'].mean()\n# sub = pd.DataFrame(data={'prediction_id': tmp.index.tolist(), 'cancer': tmp.values.tolist()})\n# display(sub)\n# sub.to_csv('submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T10:37:03.542591Z","iopub.execute_input":"2023-01-22T10:37:03.543201Z","iopub.status.idle":"2023-01-22T10:37:03.856648Z","shell.execute_reply.started":"2023-01-22T10:37:03.543164Z","shell.execute_reply":"2023-01-22T10:37:03.855913Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/28\n画像について調べる","metadata":{}},{"cell_type":"code","source":"# !pip install -qU python-gdcm pydicom pylibjpeg\n# !pip install japanize-matplotlib\n!pip install /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nimport dicomsdl\nimport cv2\nimport os\nimport copy\nimport random\nimport pydicom\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# import japanize_matplotlib\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 50)\n\nfrom torch.utils.data import Dataset, DataLoader\n#　使い方\n# https://pystyle.info/pytorch-how-to-create-custom-dataset-class/\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:29:47.452923Z","iopub.execute_input":"2023-01-28T08:29:47.453296Z","iopub.status.idle":"2023-01-28T08:30:17.074436Z","shell.execute_reply.started":"2023-01-28T08:29:47.453263Z","shell.execute_reply":"2023-01-28T08:30:17.073165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:30:17.077259Z","iopub.execute_input":"2023-01-28T08:30:17.077558Z","iopub.status.idle":"2023-01-28T08:30:17.817632Z","shell.execute_reply.started":"2023-01-28T08:30:17.077530Z","shell.execute_reply":"2023-01-28T08:30:17.816653Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_image = '/kaggle/input/rsna-breast-cancer-detection/train_images/10011/1031443799.dcm'\n# im_data = pydicom.dcmread(sample_image)\n# # print(im_data)\n# data = im_data.pixel_array\n# data.shape\n# plt.imshow(im_data.pixel_array)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T06:38:01.754762Z","iopub.execute_input":"2023-01-28T06:38:01.755274Z","iopub.status.idle":"2023-01-28T06:38:01.761272Z","shell.execute_reply.started":"2023-01-28T06:38:01.755225Z","shell.execute_reply":"2023-01-28T06:38:01.760006Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(15, 10))\n# axs = axs.flatten()\n# for i in range(8):\n#     if i <= 3:\n#         MONO = 'MONOCHROME1'\n#     else:\n#         MONO = 'MONOCHROME2'\n#     ran = random.randint(0,9000)\n#     tmp = dicom_df[dicom_df.PhotometricInterpretation == MONO].iloc[ran]\n#     p_id = tmp.patient_id\n#     i_id = tmp.image_id\n#     pas = f'/kaggle/input/rsna-breast-cancer-detection/train_images/{p_id}/{i_id}.dcm'\n#     im_data = pydicom.dcmread(pas)\n#     axs[i].imshow(im_data.pixel_array)\n#     axs[i].axis('off')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T02:14:48.473237Z","iopub.execute_input":"2023-01-28T02:14:48.473956Z","iopub.status.idle":"2023-01-28T02:15:07.620024Z","shell.execute_reply.started":"2023-01-28T02:14:48.473918Z","shell.execute_reply":"2023-01-28T02:15:07.618835Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:48:44.274589Z","iopub.execute_input":"2023-01-28T08:48:44.274990Z","iopub.status.idle":"2023-01-28T08:48:44.286369Z","shell.execute_reply.started":"2023-01-28T08:48:44.274954Z","shell.execute_reply":"2023-01-28T08:48:44.285204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = [custom_train.filename[1]]\n# data = transform_image(paths)\n# plt.imshow(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:31.025795Z","iopub.execute_input":"2023-01-28T09:56:31.026741Z","iopub.status.idle":"2023-01-28T09:56:31.031256Z","shell.execute_reply.started":"2023-01-28T09:56:31.026703Z","shell.execute_reply":"2023-01-28T09:56:31.030229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path入力\n# 余計な余白除去と左向き揃えをした画像が出力される\n# リサイズ済み\nclass Image_preprocessor:\n    def __init__(self,side='left', size=512):\n        self.side = side\n        self.size = size\n        \n    def preprocess(self, paths):\n        images = []\n        for image_path in paths:\n            image = self.read_xray(image_path)\n            image = self.crop_image(image)\n            img_side = self.determine_side(image)\n            if img_side != self.side: \n                image = cv2.flip(image, 1)\n            image = self.img2roi(image)\n            image = cv2.resize(image, (self.size, self.size))\n            images.append(image)\n        return images\n    \n    \n    def read_xray(self, path, fix_monochrome = True):\n        dicom = dicomsdl.open(path)\n        data = dicom.pixelData(storedvalue=False)  # storedvalue = True for int16 return otherwise float32\n        data = data - np.min(data)\n        data = data / np.max(data)\n        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            data = 1.0 - data\n        return data\n\n    def crop_image(self, image):\n        # 画像によっては不要な枠があるので、取り除く\n        image = image[5:-5, 5:-5]\n        return image\n    \n    def img2roi(self, image):\n        output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n        stats = output[2] # left, top, width, height, area_size\n\n        idx = stats[1:, 4].argmax() + 1\n        x1, y1, w, h = stats[idx][:4]\n        x2 = x1 + w\n        y2 = y1 + h\n\n        image_fit = image[y1: y2, x1: x2]\n\n        return image_fit\n    \n    def determine_side(self, img, threshold = 0.05):\n        \"\"\"\n        img: input image\n        threshold: for binirizing image, should be 5\n        Side is determined simply by finding more white side of the image.\n        \"\"\"\n\n        if img.dtype == 'float32':\n            ret, thresh = cv2.threshold(img, threshold, 1, 0)\n#         else:\n#             img = (255*img).astype(dtype = 'float32')\n#             ret, thresh = cv2.threshold(img, threshold, 1, 0)\n\n        width = img.shape[1]\n        # take all columns up to half image (in width), sumarize them and compare with other half\n        if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n            return 'left'\n        else:\n            return 'right'","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:06:32.142432Z","iopub.execute_input":"2023-01-28T08:06:32.143038Z","iopub.status.idle":"2023-01-28T08:06:32.157763Z","shell.execute_reply.started":"2023-01-28T08:06:32.142985Z","shell.execute_reply":"2023-01-28T08:06:32.156765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = ['/kaggle/input/rsna-breast-cancer-detection/train_images/10006/1864590858.dcm', '/kaggle/input/rsna-breast-cancer-detection/train_images/10006/462822612.dcm']\n# x = Image_preprocessor()\n# data = x.preprocess(paths)\n# plt.imshow(data[1])\n# plt.show()\n# print(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:38.337426Z","iopub.execute_input":"2023-01-28T09:56:38.337790Z","iopub.status.idle":"2023-01-28T09:56:38.342364Z","shell.execute_reply.started":"2023-01-28T09:56:38.337759Z","shell.execute_reply":"2023-01-28T09:56:38.341283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = train.copy()\n# root_dir = '/kaggle/input/rsna-breast-cancer-detection/train_images'\n# df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n# df['site_id_1'] = df['site_id_2'] = 0\n# df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n# df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n# for i in range(df.shape[0]):\n#     tmp = df.iloc[i]\n#     s_value = tmp['site_id']\n#     v_value = tmp['view']\n#     m_value = tmp['machine_id']\n#     s_name = f'site_id_{s_value}'\n#     v_name = f'view_{v_value}'\n#     m_name = f'machine_{m_value}'\n#     df.loc[i, s_name] = 1\n#     df.loc[i, v_name] = 1\n#     df.loc[i, m_name] = 1\n# train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'],axis=1)\n# train_input['age'].fillna(60, inplace=True)\n# train_input.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:13:13.541126Z","iopub.execute_input":"2023-01-28T07:13:13.541807Z","iopub.status.idle":"2023-01-28T07:13:13.546872Z","shell.execute_reply.started":"2023-01-28T07:13:13.541771Z","shell.execute_reply":"2023-01-28T07:13:13.545705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_table(df, root_dir='/kaggle/input/rsna-breast-cancer-detection/train_images'):\n    df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n    df['site_id_1'] = df['site_id_2'] = 0\n    df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n    df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n    for i in range(df.shape[0]):\n        tmp = df.iloc[i]\n        s_value = tmp['site_id']\n        v_value = tmp['view']\n        m_value = tmp['machine_id']\n        s_name = f'site_id_{s_value}'\n        v_name = f'view_{v_value}'\n        m_name = f'machine_{m_value}'\n        df.loc[i, s_name] = 1\n        df.loc[i, v_name] = 1\n        df.loc[i, m_name] = 1\n    train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n    train_input['age'].fillna(60, inplace=True)\n    return train_input\n\n# t = Image_preprocessor()\nclass RSNADataset(Dataset):\n    def __init__(self, df, root_dir, is_preprocess=False, transform=False):\n        self.table = df\n        self.root_dir = root_dir\n        self.is_preprocess = is_preprocess\n        self.transform = transform\n        \n    def __len__(self):\n        return self.table.shape[0]\n    \n    def __getitem__(self, idx):\n        df_tmp = self.table\n        if self.is_preprocess:\n            train_dataset = pre_table(df_tmp, self.root_dir)\n        else:\n            train_dataset = self.table.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n        image_name = df_tmp.filename.tolist()[idx]\n        image = t.preprocess(image_name)\n        image = torch.Tensor(image)\n        target = torch.Tensor(df_tmp['cancer'].tolist())[idx]\n        sample = {'image': image,'answer':target}\n        return sample\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:00:13.394164Z","iopub.execute_input":"2023-01-28T08:00:13.394596Z","iopub.status.idle":"2023-01-28T08:00:13.409452Z","shell.execute_reply.started":"2023-01-28T08:00:13.394561Z","shell.execute_reply":"2023-01-28T08:00:13.408188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# csv_file = '/kaggle/input/rsnacustomtrain/custom_train.csv'\n# root_dir = '/kaggle/inpu/rsna-breast-cancer-detection/train_images'\n# dataset = RSNADataset(custom_train, root_dir)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:48:19.192882Z","iopub.execute_input":"2023-01-28T07:48:19.193491Z","iopub.status.idle":"2023-01-28T07:48:19.202365Z","shell.execute_reply.started":"2023-01-28T07:48:19.193446Z","shell.execute_reply":"2023-01-28T07:48:19.201182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\nimport numpy as np\nimport pandas as pd\nfrom torch import optim\nimport torch\nCUDA_LAUNCH_BLOCKING=1\nfrom torchvision import models\nimport torch.nn as nn\nimport os\nfrom skimage import io, transform\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport skimage\nfrom skimage.color import rgb2gray, gray2rgb\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:51:06.597093Z","iopub.execute_input":"2023-01-28T08:51:06.597467Z","iopub.status.idle":"2023-01-28T08:51:07.251636Z","shell.execute_reply.started":"2023-01-28T08:51:06.597439Z","shell.execute_reply":"2023-01-28T08:51:07.250660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        paths = self.df.filename.tolist()[idx]\n        data = transform_image(paths)\n        data = torch.Tensor(data)\n        target = torch.Tensor(self.df['cancer'].tolist())[idx]\n        sample = {'data': data, 'target': target}\n        return sample\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:54.644018Z","iopub.execute_input":"2023-01-28T09:48:54.644482Z","iopub.status.idle":"2023-01-28T09:48:54.658893Z","shell.execute_reply.started":"2023-01-28T09:48:54.644444Z","shell.execute_reply":"2023-01-28T09:48:54.657585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset = TrainDataset(custom_train)\n# dataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:51:38.538837Z","iopub.execute_input":"2023-01-28T09:51:38.539728Z","iopub.status.idle":"2023-01-28T09:51:38.545690Z","shell.execute_reply.started":"2023-01-28T09:51:38.539681Z","shell.execute_reply":"2023-01-28T09:51:38.544571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for batch in dataloader:\n#     print(batch['data'].shape)\n#     print(batch['target'])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:18.226761Z","iopub.execute_input":"2023-01-28T09:54:18.227177Z","iopub.status.idle":"2023-01-28T09:54:18.232252Z","shell.execute_reply.started":"2023-01-28T09:54:18.227141Z","shell.execute_reply":"2023-01-28T09:54:18.230845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nfrom pprint import pprint\npprint(timm.list_models(pretrained = True))","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.272794Z","iopub.execute_input":"2023-01-28T09:48:58.273798Z","iopub.status.idle":"2023-01-28T09:48:58.292477Z","shell.execute_reply.started":"2023-01-28T09:48:58.273758Z","shell.execute_reply":"2023-01-28T09:48:58.291411Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tmp_model = timm.create_model(model_name='resnest26d')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.308153Z","iopub.execute_input":"2023-01-28T09:48:58.308720Z","iopub.status.idle":"2023-01-28T09:48:58.583531Z","shell.execute_reply.started":"2023-01-28T09:48:58.308682Z","shell.execute_reply":"2023-01-28T09:48:58.582462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.effnet = timm.create_model(model_name = \"tf_efficientnet_b0\", pretrained = False)\n        n_features = self.effnet.classifier.in_features\n        self.effnet.classifier = nn.Linear(n_features, 1)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.effnet(x)\n        return x\nmodel = Effnet()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.585488Z","iopub.execute_input":"2023-01-28T09:48:58.585864Z","iopub.status.idle":"2023-01-28T09:48:58.704828Z","shell.execute_reply.started":"2023-01-28T09:48:58.585826Z","shell.execute_reply":"2023-01-28T09:48:58.703858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(DEVICE)\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.706437Z","iopub.execute_input":"2023-01-28T09:48:58.706807Z","iopub.status.idle":"2023-01-28T09:48:58.728464Z","shell.execute_reply.started":"2023-01-28T09:48:58.706772Z","shell.execute_reply":"2023-01-28T09:48:58.727493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters())\n","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.730716Z","iopub.execute_input":"2023-01-28T09:48:58.731547Z","iopub.status.idle":"2023-01-28T09:48:58.737794Z","shell.execute_reply.started":"2023-01-28T09:48:58.731521Z","shell.execute_reply":"2023-01-28T09:48:58.736692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TrainDataset(custom_train)\ndataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.739381Z","iopub.execute_input":"2023-01-28T09:48:58.740007Z","iopub.status.idle":"2023-01-28T09:48:58.746471Z","shell.execute_reply.started":"2023-01-28T09:48:58.739972Z","shell.execute_reply":"2023-01-28T09:48:58.745576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.train()\n# for data in dataloader:\n#     optimizer.zero_grad()\n#     X = data['data'].float().to(DEVICE)\n#     y = data['target'].float().to(DEVICE)\n#     pred = model(X)\n#     loss = criterion(pred, y)\n#     loss.backward()\n#     optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:04.182053Z","iopub.execute_input":"2023-01-28T09:54:04.182435Z","iopub.status.idle":"2023-01-28T09:54:04.188058Z","shell.execute_reply.started":"2023-01-28T09:54:04.182404Z","shell.execute_reply":"2023-01-28T09:54:04.186985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/29","metadata":{}},{"cell_type":"code","source":"!pip install -U pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg pydicom python-gdcm","metadata":{"execution":{"iopub.status.busy":"2023-01-29T05:17:06.100029Z","iopub.execute_input":"2023-01-29T05:17:06.100417Z","iopub.status.idle":"2023-01-29T05:17:19.245759Z","shell.execute_reply.started":"2023-01-29T05:17:06.100386Z","shell.execute_reply":"2023-01-29T05:17:19.244506Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting pylibjpeg\n  Downloading pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\nCollecting pylibjpeg-openjpeg\n  Downloading pylibjpeg_openjpeg-1.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting pylibjpeg-libjpeg\n  Downloading pylibjpeg_libjpeg-1.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\nCollecting python-gdcm\n  Downloading python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\nInstalling collected packages: python-gdcm, pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg\nSuccessfully installed pylibjpeg-1.4.0 pylibjpeg-libjpeg-1.3.3 pylibjpeg-openjpeg-1.3.1 python-gdcm-3.0.20\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport pydicom\nimport gdcm\nimport pylibjpeg\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-01-29T05:20:58.450552Z","iopub.execute_input":"2023-01-29T05:20:58.450923Z","iopub.status.idle":"2023-01-29T05:20:58.456018Z","shell.execute_reply.started":"2023-01-29T05:20:58.450892Z","shell.execute_reply":"2023-01-29T05:20:58.454880Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-29T05:07:18.694011Z","iopub.execute_input":"2023-01-29T05:07:18.694629Z","iopub.status.idle":"2023-01-29T05:07:19.649424Z","shell.execute_reply.started":"2023-01-29T05:07:18.694594Z","shell.execute_reply":"2023-01-29T05:07:19.648288Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-29T05:11:03.643879Z","iopub.execute_input":"2023-01-29T05:11:03.644416Z","iopub.status.idle":"2023-01-29T05:11:03.655931Z","shell.execute_reply.started":"2023-01-29T05:11:03.644381Z","shell.execute_reply":"2023-01-29T05:11:03.654300Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        f = self.df.filename.tolist()[index]\n        image = transform_image(f)\n        target = torch.Tensor(self.df.cancer.tolist())[index]\n        image = torch.Tensor(image)\n        target = target.unsqueeze(dim=0)\n#         image = image.unsqueeze(dim=0)\n        send = {'image': image, 'target': target}\n        return send","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:25:45.015112Z","iopub.execute_input":"2023-01-29T06:25:45.015475Z","iopub.status.idle":"2023-01-29T06:25:45.022543Z","shell.execute_reply.started":"2023-01-29T06:25:45.015445Z","shell.execute_reply":"2023-01-29T06:25:45.021580Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"tmp_dataset = TrainDataset(custom_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:25:45.130695Z","iopub.execute_input":"2023-01-29T06:25:45.131663Z","iopub.status.idle":"2023-01-29T06:25:45.136544Z","shell.execute_reply.started":"2023-01-29T06:25:45.131628Z","shell.execute_reply":"2023-01-29T06:25:45.135265Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"tmp_dataloader = DataLoader(tmp_dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:25:45.284038Z","iopub.execute_input":"2023-01-29T06:25:45.286015Z","iopub.status.idle":"2023-01-29T06:25:45.290592Z","shell.execute_reply.started":"2023-01-29T06:25:45.285972Z","shell.execute_reply":"2023-01-29T06:25:45.289414Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"tmp = tmp_dataloader.__iter__()","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:25:45.413071Z","iopub.execute_input":"2023-01-29T06:25:45.413410Z","iopub.status.idle":"2023-01-29T06:25:45.418910Z","shell.execute_reply.started":"2023-01-29T06:25:45.413381Z","shell.execute_reply":"2023-01-29T06:25:45.417804Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"data = tmp.next()","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:25:47.148878Z","iopub.execute_input":"2023-01-29T06:25:47.149313Z","iopub.status.idle":"2023-01-29T06:26:02.145783Z","shell.execute_reply.started":"2023-01-29T06:25:47.149269Z","shell.execute_reply":"2023-01-29T06:26:02.144591Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"x = data['target']","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:26:06.945907Z","iopub.execute_input":"2023-01-29T06:26:06.946260Z","iopub.status.idle":"2023-01-29T06:26:06.951188Z","shell.execute_reply.started":"2023-01-29T06:26:06.946231Z","shell.execute_reply":"2023-01-29T06:26:06.950076Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:27:10.932394Z","iopub.execute_input":"2023-01-29T06:27:10.932761Z","iopub.status.idle":"2023-01-29T06:27:10.940147Z","shell.execute_reply.started":"2023-01-29T06:27:10.932713Z","shell.execute_reply":"2023-01-29T06:27:10.939157Z"},"trusted":true},"execution_count":158,"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]])"},"metadata":{}}]},{"cell_type":"code","source":"x.unsqueeze(dim=1).shape","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:12:42.157324Z","iopub.execute_input":"2023-01-29T06:12:42.157680Z","iopub.status.idle":"2023-01-29T06:12:42.165305Z","shell.execute_reply.started":"2023-01-29T06:12:42.157649Z","shell.execute_reply":"2023-01-29T06:12:42.164230Z"},"trusted":true},"execution_count":133,"outputs":[{"execution_count":133,"output_type":"execute_result","data":{"text/plain":"torch.Size([10, 1, 512, 512])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n","metadata":{"execution":{"iopub.status.busy":"2023-01-29T05:39:17.724204Z","iopub.execute_input":"2023-01-29T05:39:17.724602Z","iopub.status.idle":"2023-01-29T05:39:17.730013Z","shell.execute_reply.started":"2023-01-29T05:39:17.724571Z","shell.execute_reply":"2023-01-29T05:39:17.728796Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.pool = nn.MaxPool2d(2, stride=2)\n        \n        self.conv1 = nn.Conv2d(1, 16, 3)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n        \n        self.fc1 = nn.Linear(20482880, 100)\n        self.fc2 = nn.Linear(100, 50)\n        self.fc3 = nn.Linear(50, 10)\n        self.fc4 = nn.Linear(10, 1)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = x.view(-1, 20482880)\n        x = self.fc1(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.fc4(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:20:11.354629Z","iopub.execute_input":"2023-01-29T06:20:11.355305Z","iopub.status.idle":"2023-01-29T06:20:11.364070Z","shell.execute_reply.started":"2023-01-29T06:20:11.355270Z","shell.execute_reply":"2023-01-29T06:20:11.362918Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ndevice = torch.device(\"cuda:0\")\nnet = Net()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:36:56.581168Z","iopub.execute_input":"2023-01-29T06:36:56.581712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(10):\n    for data in tmp_dataloader:\n        inputs = data['image']\n        inputs = inputs.unsqueeze(dim=1)\n        labels = data['target']\n        inputs, labels = inputs.to(device), labels.to(device)\n        print(inputs.shape)\n        print(labels.shape)\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        print(outputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        print(lables)\n\n    for data in tmp_dataloader:\n        inputs = data['image']\n        inputs = inputs.unsqueeze(dim=1)\n        labels = data['target']\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)","metadata":{"execution":{"iopub.status.busy":"2023-01-29T06:30:41.413243Z","iopub.execute_input":"2023-01-29T06:30:41.413624Z","iopub.status.idle":"2023-01-29T06:30:56.661127Z","shell.execute_reply.started":"2023-01-29T06:30:41.413593Z","shell.execute_reply":"2023-01-29T06:30:56.659637Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stdout","text":"torch.Size([10, 1, 512, 512])\ntorch.Size([10, 1])\ntensor([[0.0307]], device='cuda:0', grad_fn=<AddmmBackward0>)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1878026699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1164\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (10)."],"ename":"ValueError","evalue":"Expected input batch_size (1) to match target batch_size (10).","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}