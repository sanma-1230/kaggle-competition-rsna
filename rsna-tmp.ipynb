{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TMP notebook\ncompetition : RSNA Screening Mammography Breast Cancer Detection  \nurl : https://www.kaggle.com/competitions/rsna-breast-cancer-detection","metadata":{}},{"cell_type":"markdown","source":"# 2023/1/22\nテーブルデータのみのlightgbmでどれくらい精度出るか検証  \n* 交差検証なし、パラメータチューニングなし\n\n## 結果\n* LB - 0.04","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import lightgbm as lgb\n# from sklearn.metrics import f1_score\n# from sklearn.model_selection import train_test_split\n# import warnings\n# warnings.simplefilter('ignore')\n\n# def pre_view(df):\n#     if 'view' in df.columns.tolist():\n#         df['view'] = df['view'].apply(lambda x: x if x=='CC' or x=='MLO' else 'others')\n#     else:\n#         pass\n#     return df\n\n# train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n# test = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n# submit = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/sample_submission.csv')\n\n# column = ['laterality', 'view', 'age', 'implant', 'cancer']\n# new_train = train[column]\n# new_train = new_train.dropna()\n# new_train = pre_view(new_train)\n# new_train_dum = pd.get_dummies(new_train)\n# train_cancer = new_train_dum[new_train_dum.cancer==1]\n# train_no_cancer = new_train_dum[new_train_dum.cancer==0]\n# tmp = train_no_cancer.sample(n=1158, random_state=0)\n# concat_train = pd.concat([train_cancer, tmp])\n\n# concat_train = concat_train.reset_index()\n# X = concat_train.drop(columns=['cancer'])\n# y = concat_train[['cancer']]\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n# # X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0, stratify=y_test)\n\n# model = lgb.LGBMClassifier(random_state=0)\n# model.fit(X_train, y_train)\n# pred = model.predict(X_test)\n# print(f1_score(y_test, pred))\n\n# tmp = test[['laterality', 'view', 'age', 'implant']]\n# tmp = pre_view(tmp)\n# tmp_ = pd.concat([new_train, tmp])\n# tmp_dum = pd.get_dummies(tmp_)\n# tmp_dum = tmp_dum.reset_index()\n# test_X = tmp_dum.iloc[new_train.shape[0]:]\n# test_X = test_X.drop(columns=['cancer'])\n# test_pred = model.predict(test_X)\n# print(test_pred)\n# test_copy = test.copy()\n# test_copy['pred'] = test_pred\n# tmp = test_copy.groupby('prediction_id')['pred'].mean()\n# sub = pd.DataFrame(data={'prediction_id': tmp.index.tolist(), 'cancer': tmp.values.tolist()})\n# display(sub)\n# sub.to_csv('submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T10:37:03.542591Z","iopub.execute_input":"2023-01-22T10:37:03.543201Z","iopub.status.idle":"2023-01-22T10:37:03.856648Z","shell.execute_reply.started":"2023-01-22T10:37:03.543164Z","shell.execute_reply":"2023-01-22T10:37:03.855913Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/28\n画像について調べる","metadata":{}},{"cell_type":"code","source":"# !pip install -qU python-gdcm pydicom pylibjpeg\n# !pip install japanize-matplotlib\n!pip install /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nimport dicomsdl\nimport cv2\nimport os\nimport copy\nimport random\nimport pydicom\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# import japanize_matplotlib\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 50)\n\nfrom torch.utils.data import Dataset, DataLoader\n#　使い方\n# https://pystyle.info/pytorch-how-to-create-custom-dataset-class/\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:29:47.452923Z","iopub.execute_input":"2023-01-28T08:29:47.453296Z","iopub.status.idle":"2023-01-28T08:30:17.074436Z","shell.execute_reply.started":"2023-01-28T08:29:47.453263Z","shell.execute_reply":"2023-01-28T08:30:17.073165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:30:17.077259Z","iopub.execute_input":"2023-01-28T08:30:17.077558Z","iopub.status.idle":"2023-01-28T08:30:17.817632Z","shell.execute_reply.started":"2023-01-28T08:30:17.077530Z","shell.execute_reply":"2023-01-28T08:30:17.816653Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_image = '/kaggle/input/rsna-breast-cancer-detection/train_images/10011/1031443799.dcm'\n# im_data = pydicom.dcmread(sample_image)\n# # print(im_data)\n# data = im_data.pixel_array\n# data.shape\n# plt.imshow(im_data.pixel_array)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T06:38:01.754762Z","iopub.execute_input":"2023-01-28T06:38:01.755274Z","iopub.status.idle":"2023-01-28T06:38:01.761272Z","shell.execute_reply.started":"2023-01-28T06:38:01.755225Z","shell.execute_reply":"2023-01-28T06:38:01.760006Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(15, 10))\n# axs = axs.flatten()\n# for i in range(8):\n#     if i <= 3:\n#         MONO = 'MONOCHROME1'\n#     else:\n#         MONO = 'MONOCHROME2'\n#     ran = random.randint(0,9000)\n#     tmp = dicom_df[dicom_df.PhotometricInterpretation == MONO].iloc[ran]\n#     p_id = tmp.patient_id\n#     i_id = tmp.image_id\n#     pas = f'/kaggle/input/rsna-breast-cancer-detection/train_images/{p_id}/{i_id}.dcm'\n#     im_data = pydicom.dcmread(pas)\n#     axs[i].imshow(im_data.pixel_array)\n#     axs[i].axis('off')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T02:14:48.473237Z","iopub.execute_input":"2023-01-28T02:14:48.473956Z","iopub.status.idle":"2023-01-28T02:15:07.620024Z","shell.execute_reply.started":"2023-01-28T02:14:48.473918Z","shell.execute_reply":"2023-01-28T02:15:07.618835Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:48:44.274589Z","iopub.execute_input":"2023-01-28T08:48:44.274990Z","iopub.status.idle":"2023-01-28T08:48:44.286369Z","shell.execute_reply.started":"2023-01-28T08:48:44.274954Z","shell.execute_reply":"2023-01-28T08:48:44.285204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = [custom_train.filename[1]]\n# data = transform_image(paths)\n# plt.imshow(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:31.025795Z","iopub.execute_input":"2023-01-28T09:56:31.026741Z","iopub.status.idle":"2023-01-28T09:56:31.031256Z","shell.execute_reply.started":"2023-01-28T09:56:31.026703Z","shell.execute_reply":"2023-01-28T09:56:31.030229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path入力\n# 余計な余白除去と左向き揃えをした画像が出力される\n# リサイズ済み\nclass Image_preprocessor:\n    def __init__(self,side='left', size=512):\n        self.side = side\n        self.size = size\n        \n    def preprocess(self, paths):\n        images = []\n        for image_path in paths:\n            image = self.read_xray(image_path)\n            image = self.crop_image(image)\n            img_side = self.determine_side(image)\n            if img_side != self.side: \n                image = cv2.flip(image, 1)\n            image = self.img2roi(image)\n            image = cv2.resize(image, (self.size, self.size))\n            images.append(image)\n        return images\n    \n    \n    def read_xray(self, path, fix_monochrome = True):\n        dicom = dicomsdl.open(path)\n        data = dicom.pixelData(storedvalue=False)  # storedvalue = True for int16 return otherwise float32\n        data = data - np.min(data)\n        data = data / np.max(data)\n        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            data = 1.0 - data\n        return data\n\n    def crop_image(self, image):\n        # 画像によっては不要な枠があるので、取り除く\n        image = image[5:-5, 5:-5]\n        return image\n    \n    def img2roi(self, image):\n        output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n        stats = output[2] # left, top, width, height, area_size\n\n        idx = stats[1:, 4].argmax() + 1\n        x1, y1, w, h = stats[idx][:4]\n        x2 = x1 + w\n        y2 = y1 + h\n\n        image_fit = image[y1: y2, x1: x2]\n\n        return image_fit\n    \n    def determine_side(self, img, threshold = 0.05):\n        \"\"\"\n        img: input image\n        threshold: for binirizing image, should be 5\n        Side is determined simply by finding more white side of the image.\n        \"\"\"\n\n        if img.dtype == 'float32':\n            ret, thresh = cv2.threshold(img, threshold, 1, 0)\n#         else:\n#             img = (255*img).astype(dtype = 'float32')\n#             ret, thresh = cv2.threshold(img, threshold, 1, 0)\n\n        width = img.shape[1]\n        # take all columns up to half image (in width), sumarize them and compare with other half\n        if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n            return 'left'\n        else:\n            return 'right'","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:06:32.142432Z","iopub.execute_input":"2023-01-28T08:06:32.143038Z","iopub.status.idle":"2023-01-28T08:06:32.157763Z","shell.execute_reply.started":"2023-01-28T08:06:32.142985Z","shell.execute_reply":"2023-01-28T08:06:32.156765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = ['/kaggle/input/rsna-breast-cancer-detection/train_images/10006/1864590858.dcm', '/kaggle/input/rsna-breast-cancer-detection/train_images/10006/462822612.dcm']\n# x = Image_preprocessor()\n# data = x.preprocess(paths)\n# plt.imshow(data[1])\n# plt.show()\n# print(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:38.337426Z","iopub.execute_input":"2023-01-28T09:56:38.337790Z","iopub.status.idle":"2023-01-28T09:56:38.342364Z","shell.execute_reply.started":"2023-01-28T09:56:38.337759Z","shell.execute_reply":"2023-01-28T09:56:38.341283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = train.copy()\n# root_dir = '/kaggle/input/rsna-breast-cancer-detection/train_images'\n# df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n# df['site_id_1'] = df['site_id_2'] = 0\n# df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n# df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n# for i in range(df.shape[0]):\n#     tmp = df.iloc[i]\n#     s_value = tmp['site_id']\n#     v_value = tmp['view']\n#     m_value = tmp['machine_id']\n#     s_name = f'site_id_{s_value}'\n#     v_name = f'view_{v_value}'\n#     m_name = f'machine_{m_value}'\n#     df.loc[i, s_name] = 1\n#     df.loc[i, v_name] = 1\n#     df.loc[i, m_name] = 1\n# train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'],axis=1)\n# train_input['age'].fillna(60, inplace=True)\n# train_input.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:13:13.541126Z","iopub.execute_input":"2023-01-28T07:13:13.541807Z","iopub.status.idle":"2023-01-28T07:13:13.546872Z","shell.execute_reply.started":"2023-01-28T07:13:13.541771Z","shell.execute_reply":"2023-01-28T07:13:13.545705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_table(df, root_dir='/kaggle/input/rsna-breast-cancer-detection/train_images'):\n    df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n    df['site_id_1'] = df['site_id_2'] = 0\n    df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n    df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n    for i in range(df.shape[0]):\n        tmp = df.iloc[i]\n        s_value = tmp['site_id']\n        v_value = tmp['view']\n        m_value = tmp['machine_id']\n        s_name = f'site_id_{s_value}'\n        v_name = f'view_{v_value}'\n        m_name = f'machine_{m_value}'\n        df.loc[i, s_name] = 1\n        df.loc[i, v_name] = 1\n        df.loc[i, m_name] = 1\n    train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n    train_input['age'].fillna(60, inplace=True)\n    return train_input\n\n# t = Image_preprocessor()\nclass RSNADataset(Dataset):\n    def __init__(self, df, root_dir, is_preprocess=False, transform=False):\n        self.table = df\n        self.root_dir = root_dir\n        self.is_preprocess = is_preprocess\n        self.transform = transform\n        \n    def __len__(self):\n        return self.table.shape[0]\n    \n    def __getitem__(self, idx):\n        df_tmp = self.table\n        if self.is_preprocess:\n            train_dataset = pre_table(df_tmp, self.root_dir)\n        else:\n            train_dataset = self.table.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n        image_name = df_tmp.filename.tolist()[idx]\n        image = t.preprocess(image_name)\n        image = torch.Tensor(image)\n        target = torch.Tensor(df_tmp['cancer'].tolist())[idx]\n        sample = {'image': image,'answer':target}\n        return sample\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:00:13.394164Z","iopub.execute_input":"2023-01-28T08:00:13.394596Z","iopub.status.idle":"2023-01-28T08:00:13.409452Z","shell.execute_reply.started":"2023-01-28T08:00:13.394561Z","shell.execute_reply":"2023-01-28T08:00:13.408188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# csv_file = '/kaggle/input/rsnacustomtrain/custom_train.csv'\n# root_dir = '/kaggle/inpu/rsna-breast-cancer-detection/train_images'\n# dataset = RSNADataset(custom_train, root_dir)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:48:19.192882Z","iopub.execute_input":"2023-01-28T07:48:19.193491Z","iopub.status.idle":"2023-01-28T07:48:19.202365Z","shell.execute_reply.started":"2023-01-28T07:48:19.193446Z","shell.execute_reply":"2023-01-28T07:48:19.201182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\nimport numpy as np\nimport pandas as pd\nfrom torch import optim\nimport torch\nCUDA_LAUNCH_BLOCKING=1\nfrom torchvision import models\nimport torch.nn as nn\nimport os\nfrom skimage import io, transform\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport skimage\nfrom skimage.color import rgb2gray, gray2rgb\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:51:06.597093Z","iopub.execute_input":"2023-01-28T08:51:06.597467Z","iopub.status.idle":"2023-01-28T08:51:07.251636Z","shell.execute_reply.started":"2023-01-28T08:51:06.597439Z","shell.execute_reply":"2023-01-28T08:51:07.250660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        paths = self.df.filename.tolist()[idx]\n        data = transform_image(paths)\n        data = torch.Tensor(data)\n        target = torch.Tensor(self.df['cancer'].tolist())[idx]\n        sample = {'data': data, 'target': target}\n        return sample\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:54.644018Z","iopub.execute_input":"2023-01-28T09:48:54.644482Z","iopub.status.idle":"2023-01-28T09:48:54.658893Z","shell.execute_reply.started":"2023-01-28T09:48:54.644444Z","shell.execute_reply":"2023-01-28T09:48:54.657585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset = TrainDataset(custom_train)\n# dataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:51:38.538837Z","iopub.execute_input":"2023-01-28T09:51:38.539728Z","iopub.status.idle":"2023-01-28T09:51:38.545690Z","shell.execute_reply.started":"2023-01-28T09:51:38.539681Z","shell.execute_reply":"2023-01-28T09:51:38.544571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for batch in dataloader:\n#     print(batch['data'].shape)\n#     print(batch['target'])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:18.226761Z","iopub.execute_input":"2023-01-28T09:54:18.227177Z","iopub.status.idle":"2023-01-28T09:54:18.232252Z","shell.execute_reply.started":"2023-01-28T09:54:18.227141Z","shell.execute_reply":"2023-01-28T09:54:18.230845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nfrom pprint import pprint\npprint(timm.list_models(pretrained = True))","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.272794Z","iopub.execute_input":"2023-01-28T09:48:58.273798Z","iopub.status.idle":"2023-01-28T09:48:58.292477Z","shell.execute_reply.started":"2023-01-28T09:48:58.273758Z","shell.execute_reply":"2023-01-28T09:48:58.291411Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tmp_model = timm.create_model(model_name='resnest26d')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.308153Z","iopub.execute_input":"2023-01-28T09:48:58.308720Z","iopub.status.idle":"2023-01-28T09:48:58.583531Z","shell.execute_reply.started":"2023-01-28T09:48:58.308682Z","shell.execute_reply":"2023-01-28T09:48:58.582462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.effnet = timm.create_model(model_name = \"tf_efficientnet_b0\", pretrained = False)\n        n_features = self.effnet.classifier.in_features\n        self.effnet.classifier = nn.Linear(n_features, 1)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.effnet(x)\n        return x\nmodel = Effnet()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.585488Z","iopub.execute_input":"2023-01-28T09:48:58.585864Z","iopub.status.idle":"2023-01-28T09:48:58.704828Z","shell.execute_reply.started":"2023-01-28T09:48:58.585826Z","shell.execute_reply":"2023-01-28T09:48:58.703858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(DEVICE)\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.706437Z","iopub.execute_input":"2023-01-28T09:48:58.706807Z","iopub.status.idle":"2023-01-28T09:48:58.728464Z","shell.execute_reply.started":"2023-01-28T09:48:58.706772Z","shell.execute_reply":"2023-01-28T09:48:58.727493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters())\n","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.730716Z","iopub.execute_input":"2023-01-28T09:48:58.731547Z","iopub.status.idle":"2023-01-28T09:48:58.737794Z","shell.execute_reply.started":"2023-01-28T09:48:58.731521Z","shell.execute_reply":"2023-01-28T09:48:58.736692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TrainDataset(custom_train)\ndataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.739381Z","iopub.execute_input":"2023-01-28T09:48:58.740007Z","iopub.status.idle":"2023-01-28T09:48:58.746471Z","shell.execute_reply.started":"2023-01-28T09:48:58.739972Z","shell.execute_reply":"2023-01-28T09:48:58.745576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.train()\n# for data in dataloader:\n#     optimizer.zero_grad()\n#     X = data['data'].float().to(DEVICE)\n#     y = data['target'].float().to(DEVICE)\n#     pred = model(X)\n#     loss = criterion(pred, y)\n#     loss.backward()\n#     optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:04.182053Z","iopub.execute_input":"2023-01-28T09:54:04.182435Z","iopub.status.idle":"2023-01-28T09:54:04.188058Z","shell.execute_reply.started":"2023-01-28T09:54:04.182404Z","shell.execute_reply":"2023-01-28T09:54:04.186985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/29","metadata":{}},{"cell_type":"code","source":"!pip install -U pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg pydicom python-gdcm","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:26.356413Z","iopub.execute_input":"2023-01-30T06:19:26.356856Z","iopub.status.idle":"2023-01-30T06:19:37.417529Z","shell.execute_reply.started":"2023-01-30T06:19:26.356766Z","shell.execute_reply":"2023-01-30T06:19:37.416199Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pylibjpeg in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: pylibjpeg-openjpeg in /opt/conda/lib/python3.7/site-packages (1.3.1)\nRequirement already satisfied: pylibjpeg-libjpeg in /opt/conda/lib/python3.7/site-packages (1.3.3)\nRequirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\nRequirement already satisfied: python-gdcm in /opt/conda/lib/python3.7/site-packages (3.0.20)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport pydicom\nimport gdcm\nimport pylibjpeg\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:37.420832Z","iopub.execute_input":"2023-01-30T06:19:37.421714Z","iopub.status.idle":"2023-01-30T06:19:39.464500Z","shell.execute_reply.started":"2023-01-30T06:19:37.421677Z","shell.execute_reply":"2023-01-30T06:19:39.463474Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:39.466131Z","iopub.execute_input":"2023-01-30T06:19:39.466795Z","iopub.status.idle":"2023-01-30T06:19:40.303771Z","shell.execute_reply.started":"2023-01-30T06:19:39.466755Z","shell.execute_reply":"2023-01-30T06:19:40.302604Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:45.876274Z","iopub.execute_input":"2023-01-30T06:19:45.876763Z","iopub.status.idle":"2023-01-30T06:19:45.889483Z","shell.execute_reply.started":"2023-01-30T06:19:45.876717Z","shell.execute_reply":"2023-01-30T06:19:45.888204Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        f = self.df.filename.tolist()[index]\n        image = transform_image(f)\n        target = torch.Tensor(self.df.cancer.tolist())[index]\n        image = torch.Tensor(image)\n#         target = target.unsqueeze(dim=-1)\n#         image = image.unsqueeze(dim=0)\n        send = {'image': image, 'target': target}\n        return send","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:46.033098Z","iopub.execute_input":"2023-01-30T06:19:46.033583Z","iopub.status.idle":"2023-01-30T06:19:46.042207Z","shell.execute_reply.started":"2023-01-30T06:19:46.033534Z","shell.execute_reply":"2023-01-30T06:19:46.041144Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tmp_dataset = TrainDataset(custom_train)\ntmp_dataloader = DataLoader(tmp_dataset, batch_size=30)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:26.084944Z","iopub.execute_input":"2023-01-30T06:32:26.086176Z","iopub.status.idle":"2023-01-30T06:32:26.091186Z","shell.execute_reply.started":"2023-01-30T06:32:26.086131Z","shell.execute_reply":"2023-01-30T06:32:26.089587Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.pool = nn.MaxPool2d(2, stride=2)\n        \n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n        \n        self.fc1 = nn.Linear(32*253*253, 100)\n        self.fc2 = nn.Linear(100, 50)\n        self.fc3 = nn.Linear(50, 10)\n        self.fc4 = nn.Linear(10, 1)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = x.view(-1, 32*253*253)\n        x = self.fc1(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.fc4(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:34.216861Z","iopub.execute_input":"2023-01-30T06:32:34.217616Z","iopub.status.idle":"2023-01-30T06:32:34.229746Z","shell.execute_reply.started":"2023-01-30T06:32:34.217576Z","shell.execute_reply":"2023-01-30T06:32:34.228786Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# device = torch.device(\"cuda:0\")\nnet = Net()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:39.287764Z","iopub.execute_input":"2023-01-30T06:32:39.288790Z","iopub.status.idle":"2023-01-30T06:32:41.368496Z","shell.execute_reply.started":"2023-01-30T06:32:39.288749Z","shell.execute_reply":"2023-01-30T06:32:41.367479Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):\n    print(f'epoch:{epoch}')\n    for i, data in enumerate(tmp_dataloader):\n        print(f'i:{i}')\n        if i==20:\n            break\n        inputs = data['image']\n        labels = data['target']\n        inputs, labels = inputs.to(device), labels.to(device)\n        inputs = inputs.unsqueeze(dim=1)\n        labels = labels.unsqueeze(dim=1)\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        print(f'train_loss:{loss}')\n\n#     for data in tmp_dataloader:\n#         inputs = data['image']\n#         inputs = inputs.unsqueeze(dim=1)\n#         labels = data['target']\n#         labels = labels.unsqueeze(dim=1)\n#         inputs, labels = inputs.to(device), labels.to(device)\n#         optimizer.zero_grad()\n#         outputs = net(inputs)\n#         loss = criterion(outputs, labels)\n#         print(f'test_loss:{loss}')\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:33:00.521541Z","iopub.execute_input":"2023-01-30T06:33:00.522006Z","iopub.status.idle":"2023-01-30T06:54:05.365556Z","shell.execute_reply.started":"2023-01-30T06:33:00.521967Z","shell.execute_reply":"2023-01-30T06:54:05.363845Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"epoch:0\ni:0\ntrain_loss:-0.0\ni:1\ntrain_loss:-0.0\ni:2\ntrain_loss:-0.0\ni:3\ntrain_loss:-0.0\ni:4\ntrain_loss:-0.0\ni:5\ntrain_loss:-0.0\ni:6\ntrain_loss:-0.0\ni:7\ntrain_loss:-0.0\ni:8\ntrain_loss:-0.0\ni:9\ntrain_loss:-0.0\ni:10\ntrain_loss:-0.0\ni:11\ntrain_loss:-0.0\ni:12\ntrain_loss:-0.0\ni:13\ntrain_loss:-0.0\ni:14\ntrain_loss:-0.0\ni:15\ntrain_loss:-0.0\ni:16\ntrain_loss:-0.0\ni:17\ntrain_loss:-0.0\ni:18\ntrain_loss:-0.0\ni:19\ntrain_loss:-0.0\ni:20\nepoch:1\ni:0\ntrain_loss:-0.0\ni:1\ntrain_loss:-0.0\ni:2\ntrain_loss:-0.0\ni:3\ntrain_loss:-0.0\ni:4\ntrain_loss:-0.0\ni:5\ntrain_loss:-0.0\ni:6\ntrain_loss:-0.0\ni:7\ntrain_loss:-0.0\ni:8\ntrain_loss:-0.0\ni:9\ntrain_loss:-0.0\ni:10\ntrain_loss:-0.0\ni:11\ntrain_loss:-0.0\ni:12\ntrain_loss:-0.0\ni:13\ntrain_loss:-0.0\ni:14\ntrain_loss:-0.0\ni:15\ntrain_loss:-0.0\ni:16\ntrain_loss:-0.0\ni:17\ntrain_loss:-0.0\ni:18\ntrain_loss:-0.0\ni:19\ntrain_loss:-0.0\ni:20\nepoch:2\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2552/1569797431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch:{epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'i:{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_2552/2191819096.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_2552/3110144962.py\u001b[0m in \u001b[0;36mtransform_image\u001b[0;34m(paths, side, size, threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdicom_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicom_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36mpixel_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \"\"\"\n\u001b[0;32m-> 1887\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_pixel_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numpy.ndarray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pixel_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36mconvert_pixel_data\u001b[0;34m(self, handler_name)\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_pixel_data_using_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_pixel_data_without_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_pixel_data_using_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36m_convert_pixel_data_without_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_pixel_data_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1537\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36m_do_pixel_data_conversion\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0;31m# Use the handler to get a 1D numpy array of the pixel data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;31m# Will raise an exception if no pixel data element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pixeldata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pixel_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_pixel_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydicom/pixel_data_handlers/gdcm_handler.py\u001b[0m in \u001b[0;36mget_pixeldata\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mgdcm_data_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mgdcm_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdcm_data_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mpixel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdcm_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mpixel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_pixel_str_fileio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/_gdcm/gdcmswig.py\u001b[0m in \u001b[0;36mGetBuffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5077\u001b[0m         \u001b[0mAccess\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mraw\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5078\u001b[0m         \"\"\"\n\u001b[0;32m-> 5079\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_gdcmswig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitmap_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5081\u001b[0m \u001b[0;31m# Register Bitmap in _gdcmswig:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}