{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TMP notebook\ncompetition : RSNA Screening Mammography Breast Cancer Detection  \nurl : https://www.kaggle.com/competitions/rsna-breast-cancer-detection","metadata":{}},{"cell_type":"markdown","source":"# 2023/1/22\nテーブルデータのみのlightgbmでどれくらい精度出るか検証  \n* 交差検証なし、パラメータチューニングなし\n\n## 結果\n* LB - 0.04","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import lightgbm as lgb\n# from sklearn.metrics import f1_score\n# from sklearn.model_selection import train_test_split\n# import warnings\n# warnings.simplefilter('ignore')\n\n# def pre_view(df):\n#     if 'view' in df.columns.tolist():\n#         df['view'] = df['view'].apply(lambda x: x if x=='CC' or x=='MLO' else 'others')\n#     else:\n#         pass\n#     return df\n\n# train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n# test = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n# submit = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/sample_submission.csv')\n\n# column = ['laterality', 'view', 'age', 'implant', 'cancer']\n# new_train = train[column]\n# new_train = new_train.dropna()\n# new_train = pre_view(new_train)\n# new_train_dum = pd.get_dummies(new_train)\n# train_cancer = new_train_dum[new_train_dum.cancer==1]\n# train_no_cancer = new_train_dum[new_train_dum.cancer==0]\n# tmp = train_no_cancer.sample(n=1158, random_state=0)\n# concat_train = pd.concat([train_cancer, tmp])\n\n# concat_train = concat_train.reset_index()\n# X = concat_train.drop(columns=['cancer'])\n# y = concat_train[['cancer']]\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n# # X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0, stratify=y_test)\n\n# model = lgb.LGBMClassifier(random_state=0)\n# model.fit(X_train, y_train)\n# pred = model.predict(X_test)\n# print(f1_score(y_test, pred))\n\n# tmp = test[['laterality', 'view', 'age', 'implant']]\n# tmp = pre_view(tmp)\n# tmp_ = pd.concat([new_train, tmp])\n# tmp_dum = pd.get_dummies(tmp_)\n# tmp_dum = tmp_dum.reset_index()\n# test_X = tmp_dum.iloc[new_train.shape[0]:]\n# test_X = test_X.drop(columns=['cancer'])\n# test_pred = model.predict(test_X)\n# print(test_pred)\n# test_copy = test.copy()\n# test_copy['pred'] = test_pred\n# tmp = test_copy.groupby('prediction_id')['pred'].mean()\n# sub = pd.DataFrame(data={'prediction_id': tmp.index.tolist(), 'cancer': tmp.values.tolist()})\n# display(sub)\n# sub.to_csv('submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T10:37:03.542591Z","iopub.execute_input":"2023-01-22T10:37:03.543201Z","iopub.status.idle":"2023-01-22T10:37:03.856648Z","shell.execute_reply.started":"2023-01-22T10:37:03.543164Z","shell.execute_reply":"2023-01-22T10:37:03.855913Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/28\n画像について調べる","metadata":{}},{"cell_type":"code","source":"# !pip install -qU python-gdcm pydicom pylibjpeg\n# !pip install japanize-matplotlib\n!pip install /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nimport dicomsdl\nimport cv2\nimport os\nimport copy\nimport random\nimport pydicom\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# import japanize_matplotlib\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 50)\n\nfrom torch.utils.data import Dataset, DataLoader\n#　使い方\n# https://pystyle.info/pytorch-how-to-create-custom-dataset-class/\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:29:47.452923Z","iopub.execute_input":"2023-01-28T08:29:47.453296Z","iopub.status.idle":"2023-01-28T08:30:17.074436Z","shell.execute_reply.started":"2023-01-28T08:29:47.453263Z","shell.execute_reply":"2023-01-28T08:30:17.073165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:30:17.077259Z","iopub.execute_input":"2023-01-28T08:30:17.077558Z","iopub.status.idle":"2023-01-28T08:30:17.817632Z","shell.execute_reply.started":"2023-01-28T08:30:17.077530Z","shell.execute_reply":"2023-01-28T08:30:17.816653Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_image = '/kaggle/input/rsna-breast-cancer-detection/train_images/10011/1031443799.dcm'\n# im_data = pydicom.dcmread(sample_image)\n# # print(im_data)\n# data = im_data.pixel_array\n# data.shape\n# plt.imshow(im_data.pixel_array)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T06:38:01.754762Z","iopub.execute_input":"2023-01-28T06:38:01.755274Z","iopub.status.idle":"2023-01-28T06:38:01.761272Z","shell.execute_reply.started":"2023-01-28T06:38:01.755225Z","shell.execute_reply":"2023-01-28T06:38:01.760006Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(15, 10))\n# axs = axs.flatten()\n# for i in range(8):\n#     if i <= 3:\n#         MONO = 'MONOCHROME1'\n#     else:\n#         MONO = 'MONOCHROME2'\n#     ran = random.randint(0,9000)\n#     tmp = dicom_df[dicom_df.PhotometricInterpretation == MONO].iloc[ran]\n#     p_id = tmp.patient_id\n#     i_id = tmp.image_id\n#     pas = f'/kaggle/input/rsna-breast-cancer-detection/train_images/{p_id}/{i_id}.dcm'\n#     im_data = pydicom.dcmread(pas)\n#     axs[i].imshow(im_data.pixel_array)\n#     axs[i].axis('off')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T02:14:48.473237Z","iopub.execute_input":"2023-01-28T02:14:48.473956Z","iopub.status.idle":"2023-01-28T02:15:07.620024Z","shell.execute_reply.started":"2023-01-28T02:14:48.473918Z","shell.execute_reply":"2023-01-28T02:15:07.618835Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:48:44.274589Z","iopub.execute_input":"2023-01-28T08:48:44.274990Z","iopub.status.idle":"2023-01-28T08:48:44.286369Z","shell.execute_reply.started":"2023-01-28T08:48:44.274954Z","shell.execute_reply":"2023-01-28T08:48:44.285204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = [custom_train.filename[1]]\n# data = transform_image(paths)\n# plt.imshow(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:31.025795Z","iopub.execute_input":"2023-01-28T09:56:31.026741Z","iopub.status.idle":"2023-01-28T09:56:31.031256Z","shell.execute_reply.started":"2023-01-28T09:56:31.026703Z","shell.execute_reply":"2023-01-28T09:56:31.030229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path入力\n# 余計な余白除去と左向き揃えをした画像が出力される\n# リサイズ済み\nclass Image_preprocessor:\n    def __init__(self,side='left', size=512):\n        self.side = side\n        self.size = size\n        \n    def preprocess(self, paths):\n        images = []\n        for image_path in paths:\n            image = self.read_xray(image_path)\n            image = self.crop_image(image)\n            img_side = self.determine_side(image)\n            if img_side != self.side: \n                image = cv2.flip(image, 1)\n            image = self.img2roi(image)\n            image = cv2.resize(image, (self.size, self.size))\n            images.append(image)\n        return images\n    \n    \n    def read_xray(self, path, fix_monochrome = True):\n        dicom = dicomsdl.open(path)\n        data = dicom.pixelData(storedvalue=False)  # storedvalue = True for int16 return otherwise float32\n        data = data - np.min(data)\n        data = data / np.max(data)\n        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            data = 1.0 - data\n        return data\n\n    def crop_image(self, image):\n        # 画像によっては不要な枠があるので、取り除く\n        image = image[5:-5, 5:-5]\n        return image\n    \n    def img2roi(self, image):\n        output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n        stats = output[2] # left, top, width, height, area_size\n\n        idx = stats[1:, 4].argmax() + 1\n        x1, y1, w, h = stats[idx][:4]\n        x2 = x1 + w\n        y2 = y1 + h\n\n        image_fit = image[y1: y2, x1: x2]\n\n        return image_fit\n    \n    def determine_side(self, img, threshold = 0.05):\n        \"\"\"\n        img: input image\n        threshold: for binirizing image, should be 5\n        Side is determined simply by finding more white side of the image.\n        \"\"\"\n\n        if img.dtype == 'float32':\n            ret, thresh = cv2.threshold(img, threshold, 1, 0)\n#         else:\n#             img = (255*img).astype(dtype = 'float32')\n#             ret, thresh = cv2.threshold(img, threshold, 1, 0)\n\n        width = img.shape[1]\n        # take all columns up to half image (in width), sumarize them and compare with other half\n        if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n            return 'left'\n        else:\n            return 'right'","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:06:32.142432Z","iopub.execute_input":"2023-01-28T08:06:32.143038Z","iopub.status.idle":"2023-01-28T08:06:32.157763Z","shell.execute_reply.started":"2023-01-28T08:06:32.142985Z","shell.execute_reply":"2023-01-28T08:06:32.156765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = ['/kaggle/input/rsna-breast-cancer-detection/train_images/10006/1864590858.dcm', '/kaggle/input/rsna-breast-cancer-detection/train_images/10006/462822612.dcm']\n# x = Image_preprocessor()\n# data = x.preprocess(paths)\n# plt.imshow(data[1])\n# plt.show()\n# print(data[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:56:38.337426Z","iopub.execute_input":"2023-01-28T09:56:38.337790Z","iopub.status.idle":"2023-01-28T09:56:38.342364Z","shell.execute_reply.started":"2023-01-28T09:56:38.337759Z","shell.execute_reply":"2023-01-28T09:56:38.341283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = train.copy()\n# root_dir = '/kaggle/input/rsna-breast-cancer-detection/train_images'\n# df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n# df['site_id_1'] = df['site_id_2'] = 0\n# df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n# df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n# for i in range(df.shape[0]):\n#     tmp = df.iloc[i]\n#     s_value = tmp['site_id']\n#     v_value = tmp['view']\n#     m_value = tmp['machine_id']\n#     s_name = f'site_id_{s_value}'\n#     v_name = f'view_{v_value}'\n#     m_name = f'machine_{m_value}'\n#     df.loc[i, s_name] = 1\n#     df.loc[i, v_name] = 1\n#     df.loc[i, m_name] = 1\n# train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'],axis=1)\n# train_input['age'].fillna(60, inplace=True)\n# train_input.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:13:13.541126Z","iopub.execute_input":"2023-01-28T07:13:13.541807Z","iopub.status.idle":"2023-01-28T07:13:13.546872Z","shell.execute_reply.started":"2023-01-28T07:13:13.541771Z","shell.execute_reply":"2023-01-28T07:13:13.545705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_table(df, root_dir='/kaggle/input/rsna-breast-cancer-detection/train_images'):\n    df['filename'] = root_dir+'/'+df.patient_id.astype(str)+'/'+df.image_id.astype(str)+'.dcm'\n    df['site_id_1'] = df['site_id_2'] = 0\n    df['view_MLO'] = df['view_CC'] = df['view_AT'] = df['view_LM'] = df['view_ML'] = df['view_LMO'] = 0\n    df['machine_49'] = df['machine_48'] = df['machine_29'] = df['machine_21'] = df['machine_93'] = df['machine_216'] = df['machine_210'] = df['machine_170'] = df['machine_190'] = df['machine_197'] = 0\n    for i in range(df.shape[0]):\n        tmp = df.iloc[i]\n        s_value = tmp['site_id']\n        v_value = tmp['view']\n        m_value = tmp['machine_id']\n        s_name = f'site_id_{s_value}'\n        v_name = f'view_{v_value}'\n        m_name = f'machine_{m_value}'\n        df.loc[i, s_name] = 1\n        df.loc[i, v_name] = 1\n        df.loc[i, m_name] = 1\n    train_input = df.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n    train_input['age'].fillna(60, inplace=True)\n    return train_input\n\n# t = Image_preprocessor()\nclass RSNADataset(Dataset):\n    def __init__(self, df, root_dir, is_preprocess=False, transform=False):\n        self.table = df\n        self.root_dir = root_dir\n        self.is_preprocess = is_preprocess\n        self.transform = transform\n        \n    def __len__(self):\n        return self.table.shape[0]\n    \n    def __getitem__(self, idx):\n        df_tmp = self.table\n        if self.is_preprocess:\n            train_dataset = pre_table(df_tmp, self.root_dir)\n        else:\n            train_dataset = self.table.drop(['site_id', 'patient_id', 'image_id', 'laterality', 'view', 'cancer', 'biopsy', 'filename', 'invasive', 'BIRADS', 'density', 'machine_id', 'difficult_negative_case'], axis=1)\n        image_name = df_tmp.filename.tolist()[idx]\n        image = t.preprocess(image_name)\n        image = torch.Tensor(image)\n        target = torch.Tensor(df_tmp['cancer'].tolist())[idx]\n        sample = {'image': image,'answer':target}\n        return sample\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:00:13.394164Z","iopub.execute_input":"2023-01-28T08:00:13.394596Z","iopub.status.idle":"2023-01-28T08:00:13.409452Z","shell.execute_reply.started":"2023-01-28T08:00:13.394561Z","shell.execute_reply":"2023-01-28T08:00:13.408188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# csv_file = '/kaggle/input/rsnacustomtrain/custom_train.csv'\n# root_dir = '/kaggle/inpu/rsna-breast-cancer-detection/train_images'\n# dataset = RSNADataset(custom_train, root_dir)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:48:19.192882Z","iopub.execute_input":"2023-01-28T07:48:19.193491Z","iopub.status.idle":"2023-01-28T07:48:19.202365Z","shell.execute_reply.started":"2023-01-28T07:48:19.193446Z","shell.execute_reply":"2023-01-28T07:48:19.201182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\nimport numpy as np\nimport pandas as pd\nfrom torch import optim\nimport torch\nCUDA_LAUNCH_BLOCKING=1\nfrom torchvision import models\nimport torch.nn as nn\nimport os\nfrom skimage import io, transform\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport skimage\nfrom skimage.color import rgb2gray, gray2rgb\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:51:06.597093Z","iopub.execute_input":"2023-01-28T08:51:06.597467Z","iopub.status.idle":"2023-01-28T08:51:07.251636Z","shell.execute_reply.started":"2023-01-28T08:51:06.597439Z","shell.execute_reply":"2023-01-28T08:51:07.250660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        paths = self.df.filename.tolist()[idx]\n        data = transform_image(paths)\n        data = torch.Tensor(data)\n        target = torch.Tensor(self.df['cancer'].tolist())[idx]\n        sample = {'data': data, 'target': target}\n        return sample\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:54.644018Z","iopub.execute_input":"2023-01-28T09:48:54.644482Z","iopub.status.idle":"2023-01-28T09:48:54.658893Z","shell.execute_reply.started":"2023-01-28T09:48:54.644444Z","shell.execute_reply":"2023-01-28T09:48:54.657585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset = TrainDataset(custom_train)\n# dataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:51:38.538837Z","iopub.execute_input":"2023-01-28T09:51:38.539728Z","iopub.status.idle":"2023-01-28T09:51:38.545690Z","shell.execute_reply.started":"2023-01-28T09:51:38.539681Z","shell.execute_reply":"2023-01-28T09:51:38.544571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for batch in dataloader:\n#     print(batch['data'].shape)\n#     print(batch['target'])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:18.226761Z","iopub.execute_input":"2023-01-28T09:54:18.227177Z","iopub.status.idle":"2023-01-28T09:54:18.232252Z","shell.execute_reply.started":"2023-01-28T09:54:18.227141Z","shell.execute_reply":"2023-01-28T09:54:18.230845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nfrom pprint import pprint\npprint(timm.list_models(pretrained = True))","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.272794Z","iopub.execute_input":"2023-01-28T09:48:58.273798Z","iopub.status.idle":"2023-01-28T09:48:58.292477Z","shell.execute_reply.started":"2023-01-28T09:48:58.273758Z","shell.execute_reply":"2023-01-28T09:48:58.291411Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tmp_model = timm.create_model(model_name='resnest26d')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.308153Z","iopub.execute_input":"2023-01-28T09:48:58.308720Z","iopub.status.idle":"2023-01-28T09:48:58.583531Z","shell.execute_reply.started":"2023-01-28T09:48:58.308682Z","shell.execute_reply":"2023-01-28T09:48:58.582462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.effnet = timm.create_model(model_name = \"tf_efficientnet_b0\", pretrained = False)\n        n_features = self.effnet.classifier.in_features\n        self.effnet.classifier = nn.Linear(n_features, 1)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.effnet(x)\n        return x\nmodel = Effnet()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.585488Z","iopub.execute_input":"2023-01-28T09:48:58.585864Z","iopub.status.idle":"2023-01-28T09:48:58.704828Z","shell.execute_reply.started":"2023-01-28T09:48:58.585826Z","shell.execute_reply":"2023-01-28T09:48:58.703858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(DEVICE)\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.706437Z","iopub.execute_input":"2023-01-28T09:48:58.706807Z","iopub.status.idle":"2023-01-28T09:48:58.728464Z","shell.execute_reply.started":"2023-01-28T09:48:58.706772Z","shell.execute_reply":"2023-01-28T09:48:58.727493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters())\n","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.730716Z","iopub.execute_input":"2023-01-28T09:48:58.731547Z","iopub.status.idle":"2023-01-28T09:48:58.737794Z","shell.execute_reply.started":"2023-01-28T09:48:58.731521Z","shell.execute_reply":"2023-01-28T09:48:58.736692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TrainDataset(custom_train)\ndataloader = DataLoader(dataset, batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:48:58.739381Z","iopub.execute_input":"2023-01-28T09:48:58.740007Z","iopub.status.idle":"2023-01-28T09:48:58.746471Z","shell.execute_reply.started":"2023-01-28T09:48:58.739972Z","shell.execute_reply":"2023-01-28T09:48:58.745576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.train()\n# for data in dataloader:\n#     optimizer.zero_grad()\n#     X = data['data'].float().to(DEVICE)\n#     y = data['target'].float().to(DEVICE)\n#     pred = model(X)\n#     loss = criterion(pred, y)\n#     loss.backward()\n#     optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:54:04.182053Z","iopub.execute_input":"2023-01-28T09:54:04.182435Z","iopub.status.idle":"2023-01-28T09:54:04.188058Z","shell.execute_reply.started":"2023-01-28T09:54:04.182404Z","shell.execute_reply":"2023-01-28T09:54:04.186985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2023/1/29","metadata":{}},{"cell_type":"code","source":"!pip install -U pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg pydicom python-gdcm","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:26.356413Z","iopub.execute_input":"2023-01-30T06:19:26.356856Z","iopub.status.idle":"2023-01-30T06:19:37.417529Z","shell.execute_reply.started":"2023-01-30T06:19:26.356766Z","shell.execute_reply":"2023-01-30T06:19:37.416199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport pydicom\nimport gdcm\nimport pylibjpeg\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:37.420832Z","iopub.execute_input":"2023-01-30T06:19:37.421714Z","iopub.status.idle":"2023-01-30T06:19:39.464500Z","shell.execute_reply.started":"2023-01-30T06:19:37.421677Z","shell.execute_reply":"2023-01-30T06:19:39.463474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ndicom_df = pd.read_csv('/kaggle/input/rsna-dicom-csv/dicom.csv')\ncustom_train = pd.read_csv('/kaggle/input/rsnacustomtrain/custom_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:39.466131Z","iopub.execute_input":"2023-01-30T06:19:39.466795Z","iopub.status.idle":"2023-01-30T06:19:40.303771Z","shell.execute_reply.started":"2023-01-30T06:19:39.466755Z","shell.execute_reply":"2023-01-30T06:19:40.302604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_image(paths, side='left', size=512, threshold=0.05):\n    dicom_data = pydicom.dcmread(paths)\n    data = np.array(dicom_data.pixel_array)\n    data = data - np.min(data)\n    data = data / np.max(data)\n    if dicom_data.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    image = data[5:-5, 5:-5]\n\n    ret, thresh = cv2.threshold(image, threshold, 1, 0)\n\n    width = image.shape[1]\n    # take all columns up to half image (in width), sumarize them and compare with other half\n    if sum(sum(thresh[:, :width // 2])) > sum(sum(thresh[:, width // 2:])): \n        image_side = 'left'\n    else:\n        image_side = 'right'\n\n    if image_side != side: \n        image = cv2.flip(image, 1)\n    output= cv2.connectedComponentsWithStats((image > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2] # left, top, width, height, area_size\n\n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n\n    image = image[y1: y2, x1: x2]\n    image = cv2.resize(image, (size, size))\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:45.876274Z","iopub.execute_input":"2023-01-30T06:19:45.876763Z","iopub.status.idle":"2023-01-30T06:19:45.889483Z","shell.execute_reply.started":"2023-01-30T06:19:45.876717Z","shell.execute_reply":"2023-01-30T06:19:45.888204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        f = self.df.filename.tolist()[index]\n        image = transform_image(f)\n        target = torch.Tensor(self.df.cancer.tolist())[index]\n        image = torch.Tensor(image)\n#         target = target.unsqueeze(dim=-1)\n#         image = image.unsqueeze(dim=0)\n        send = {'image': image, 'target': target}\n        return send","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:19:46.033098Z","iopub.execute_input":"2023-01-30T06:19:46.033583Z","iopub.status.idle":"2023-01-30T06:19:46.042207Z","shell.execute_reply.started":"2023-01-30T06:19:46.033534Z","shell.execute_reply":"2023-01-30T06:19:46.041144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_dataset = TrainDataset(custom_train)\ntmp_dataloader = DataLoader(tmp_dataset, batch_size=30)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:26.084944Z","iopub.execute_input":"2023-01-30T06:32:26.086176Z","iopub.status.idle":"2023-01-30T06:32:26.091186Z","shell.execute_reply.started":"2023-01-30T06:32:26.086131Z","shell.execute_reply":"2023-01-30T06:32:26.089587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.pool = nn.MaxPool2d(2, stride=2)\n        \n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n        \n        self.fc1 = nn.Linear(32*253*253, 100)\n        self.fc2 = nn.Linear(100, 50)\n        self.fc3 = nn.Linear(50, 10)\n        self.fc4 = nn.Linear(10, 1)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = x.view(-1, 32*253*253)\n        x = self.fc1(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.fc4(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:34.216861Z","iopub.execute_input":"2023-01-30T06:32:34.217616Z","iopub.status.idle":"2023-01-30T06:32:34.229746Z","shell.execute_reply.started":"2023-01-30T06:32:34.217576Z","shell.execute_reply":"2023-01-30T06:32:34.228786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# device = torch.device(\"cuda:0\")\nnet = Net()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:32:39.287764Z","iopub.execute_input":"2023-01-30T06:32:39.288790Z","iopub.status.idle":"2023-01-30T06:32:41.368496Z","shell.execute_reply.started":"2023-01-30T06:32:39.288749Z","shell.execute_reply":"2023-01-30T06:32:41.367479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):\n    print(f'epoch:{epoch}')\n    for i, data in enumerate(tmp_dataloader):\n        print(f'i:{i}')\n        if i==20:\n            break\n        inputs = data['image']\n        labels = data['target']\n        inputs, labels = inputs.to(device), labels.to(device)\n        inputs = inputs.unsqueeze(dim=1)\n        labels = labels.unsqueeze(dim=1)\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        print(f'train_loss:{loss}')\n\n#     for data in tmp_dataloader:\n#         inputs = data['image']\n#         inputs = inputs.unsqueeze(dim=1)\n#         labels = data['target']\n#         labels = labels.unsqueeze(dim=1)\n#         inputs, labels = inputs.to(device), labels.to(device)\n#         optimizer.zero_grad()\n#         outputs = net(inputs)\n#         loss = criterion(outputs, labels)\n#         print(f'test_loss:{loss}')\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:33:00.521541Z","iopub.execute_input":"2023-01-30T06:33:00.522006Z","iopub.status.idle":"2023-01-30T06:54:05.365556Z","shell.execute_reply.started":"2023-01-30T06:33:00.521967Z","shell.execute_reply":"2023-01-30T06:54:05.363845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2023/2/1","metadata":{}},{"cell_type":"markdown","source":"htmlをおしゃれにするやつを見つけたからやってみた","metadata":{}},{"cell_type":"code","source":"!wget http://bit.ly/3ZLyF82 -O CSS.css -q\n    \nfrom IPython.core.display import HTML\nwith open('./CSS.css', 'r') as file:\n    custom_css = file.read()\n\nHTML(custom_css)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:21:58.914929Z","iopub.execute_input":"2023-02-01T10:21:58.915271Z","iopub.status.idle":"2023-02-01T10:22:00.675000Z","shell.execute_reply.started":"2023-02-01T10:21:58.915187Z","shell.execute_reply":"2023-02-01T10:22:00.673669Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n\n:root{\n    --header1_color: #204709;\n    --header2_color: #42841F;\n    --header3_color: #6EAF4B;\n    --keyword_color: #cc241d; /* import */\n    --string_color: #79740e;\n    --number_color: #b16286;\n    --def_color: #689d6a; /* class name */\n    --property_color: #458588; /* python properties */\n    --builtin_color: #689d6a;\n    --comment_color: #9f9f9f;\n    --comment_color_2: #458588; /* equals sign */\n    --operator_color: #a221f2;\n    --font_color: #3c3836; /* general font */\n    --variable2_color: #b16286; /*self keyworda */\n    --box_color: #fffdee66;\n}\n\n\n/* h1, .h1 { */\n/*     font-family: \"Trebuchet MS\", sans-serif; */\n/*     font-size: 2em !important; */\n/*     letter-spacing: 1px; */\n/*     /1* border-bottom: 3px solid #497564; *1/ */\n/*     /1* text-transform: uppercase; *1/ */\n/*     color: var(--header1_color); */\n/*     border-bottom: 3px solid var(--header1_color); */\n/* } */\n\n/* h1.title{ */\n/*     padding:5px */\n/* } */\n\n/* div.title { */\n/*     text-align: center; */\n/*     background-color: #d3e6d23d; */\n/*     height:3em; */\n/*     border-radius: 10px; */\n/*     box-shadow: 3px 3px #536f533d; */\n/*     margin-bottom: 8px; */\n/* } */\n\n/* h2, .h2 { */\n/*     font-family: \"Trebuchet MS\"; */\n/*     font-size: 1.7em !important; */\n/*     color: var(--header2_color); */\n/* } */\n\n/* h3, .h3 { */\n/*     font-family: \"Trebuchet MS\"; */\n/*     font-size: 1.4em !important; */\n/*     color: var(--header3_color); */\n/* } */\n\n/* .jp-mod-active .jp-Collapser-child{ */\n/*     background-color: #d79921; */\n/* } */\n/* .output { */\n/*     flex-direction: row; */\n/* } */\n\n.cm-s-jupyter span.cm-variable-2{\n    color: var(--variable2_color);\n}\n\n.cm-s-jupyter span.cm-variable{\n    color: var(--font_color);\n}\n.cm-s-jupyter span.cm-number{\n    color: var(--number_color);\n}\n\n.cm-s-jupyter span.cm-def {\n    color: var(--def_color);\n}\n\n.cm-s-jupyter span.cm-keyword{\n    color: var(--keyword_color);\n    font-weight: lighter;\n}\n\n.cm-s-jupyter span.cm-property{\n    color: var(--property_color);\n}\n\n.cm-s-jupyter span.cm-builtin{\n    color: var(--builtin_color);\n}\n\n.cm-s-jupyter span.cm-string {\n    color: var(--string_color);\n}\n\n.cm-s-jupyter span.cm-comment{\n    color: var(--comment_color);\n}\n\n.cm-s-jupyter span.cm-operator{\n    color: var(--operator_color);\n}\n\nbody[data-jp-theme-light=\"true\"] .jp-Notebook .CodeMirror.cm-s-jupyter{\n    background-color: var(--box_color) !important;\n}\n\n/* body[data-jp-theme-light=\"true\"] .lm-Widget.p-Widget.jp-CodeMirrorEditor.jp-Editor.jp-InputArea-editor { */\n/*     border-color: #9b9b99 !important; */\n/*     border-style: solid none none !important; */\n/*     border-width: 2px medium medium !important; */\n/*     border-radius: 0; */\n/* } */\n\n/* /1* --- for rendering submitted notebook --- *1/ */\n/* div.text_cell_render h1 { */\n/*     font-family: \"Trebuchet MS\", sans-serif; */\n/*     font-size: 2em !important; */\n/*     letter-spacing: 1px; */\n/*     border-bottom: 3px solid var(--header1_color); */\n/*     /1* text-transform: uppercase; *1/ */\n/*     color: var(--header1_color); */\n/*     padding: 0px; */\n/*     margin-top: 5px; */\n/* } */\n\n/* div.text_cell_render h2 { */\n/*     font-family: \"Trebuchet MS\"; */\n/*     font-size: 1.7em !important; */\n/*     color: var(--header2_color); */\n/* } */\n\n/* div.text_cell_render h3 { */\n/*     font-family: \"Trebuchet MS\"; */\n/*     font-size: 1.4em !important; */\n/*     color: var(--header3_color); */\n/* } */\n\n/* .highlight .nn{ */\n/*     color: black; */\n/* } */\n\n/* .n{ */\n/*     color: black */\n/* } */\n\n/* .o{ */\n/*     color: black */\n/* } */\n\n/* .p{ */\n/*     color: black */\n/* } */\n\n.highlight .s1 {\n    color: var(--string_color);\n}\n\n/* cm-string */\n.highlight .s2 {\n    color: var(--string_color);\n}\n\n/* cm-keyword */\n.highlight .k {\n    color: var(--keyword_color);\n    font-weight: lighter;\n}\n\n.highlight .kc{\n    color: var(--keyword_color);\n    font-weight: lighter;\n}\n\n/* cm-number */\n.highlight .mi{\n    color: var(--number_color);\n}\n\n/* cm-comment */\n.highlight .c1{\n    color: var(--comment_color);\n    font-weight: lighter;\n}\n\n.highlight .mf{\n    color: var(--number_color);\n}\n\n.highlight .sd{\n    color: var(--string_color);\n    font-weight: lighter;\n}\n\n/* cm-keyword */\n.highlight .ow {\n    color: var(--keyword_color);\n    font-weight: lighter;\n}\n\n/* cm-operator */\n.highlight .o{\n    color: var(--operator_color);\n}\n\n/* cm-keyword */\n.highlight .kn{\n    color: var(--keyword_color);\n    font-weight: lighter;\n}\n\n/* cm-builtin */\n.highlight .nb{\n    color: var(--builtin_color);\n}\n\n/* class keyword */\n.highlight .nc{\n    color: var(--def_color);\n    font-weight: lighter;\n}\n\n/* cm-def */ \n.highlight .fm{\n    color: var(--def_color);\n}\n\n/* cm-keyword */\n.highlight .bp{\n    color: var(--keyword_color);\n}\n\n.highlight .si {\n  color: #BB6622;\n  font-weight: lighter;\n}\n\n/* cm-property */\na.global_indexed_symbol{\n    color: var(--property_color);\n}\n\n/* cm-def */ \n.highlight .nf{\n    color: var(--def_color);\n}\n\n/* self */\n.highlight .bp{\n    color: var(--variable2_color)\n}\n\ndiv.output_subarea.output_text{\n    padding: 16px;\n    width: 1000px;\n}\n\n.jp-RenderedHTMLCommon :not(pre) > code{\n    background-color: transparent !important;\n}\n\n/* h1.header { */\n/*     color: white !important; */\n/* } */\n\n.insights {\n    line-height: 1.7em;\n    color: #31708f;\n    background-color: #d9edf7;\n    border-color: #bce8f1;\n    padding: 15px;\n    margin-bottom: 20px;\n    border: 1px solid transparent;\n    border-radius: 4px;\n    font-family: Verdana,sans-serif;\n    font-size: 15px;\n}\n\ndiv.output_subarea {\n    padding: 0px\n}\n\ndiv.output_area pre{\n    margin: 0px\n}\n\ndiv.output_area pre {\n    margin: 5px\n}\n\n\ndiv.input_area{\n    background-color: var(--box_color) !important;\n}\n\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:23:26.201738Z","iopub.execute_input":"2023-02-01T10:23:26.202209Z","iopub.status.idle":"2023-02-01T10:23:26.308711Z","shell.execute_reply.started":"2023-02-01T10:23:26.202175Z","shell.execute_reply":"2023-02-01T10:23:26.307544Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train.age)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:24:40.803009Z","iopub.execute_input":"2023-02-01T10:24:40.803399Z","iopub.status.idle":"2023-02-01T10:24:41.063581Z","shell.execute_reply.started":"2023-02-01T10:24:40.803365Z","shell.execute_reply":"2023-02-01T10:24:41.062537Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(array([   59.,   341.,  4562.,  9344., 11092., 11321., 11511.,  4380.,\n         1530.,   529.]),\n array([26. , 32.3, 38.6, 44.9, 51.2, 57.5, 63.8, 70.1, 76.4, 82.7, 89. ]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\nplt.hist(train.age)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T10:26:06.727444Z","iopub.execute_input":"2023-02-01T10:26:06.728184Z","iopub.status.idle":"2023-02-01T10:26:07.015763Z","shell.execute_reply.started":"2023-02-01T10:26:06.728147Z","shell.execute_reply":"2023-02-01T10:26:07.014678Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(array([   59.,   341.,  4562.,  9344., 11092., 11321., 11511.,  4380.,\n         1530.,   529.]),\n array([26. , 32.3, 38.6, 44.9, 51.2, 57.5, 63.8, 70.1, 76.4, 82.7, 89. ]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}